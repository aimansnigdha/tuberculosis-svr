{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import np_utils\n",
    "from keras.layers import Conv3D, MaxPool3D, Flatten, Dense\n",
    "from keras.layers import Dropout, Input, BatchNormalization\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from keras.losses import binary_crossentropy\n",
    "from keras.optimizers import Adadelta, SGD\n",
    "from matplotlib.pyplot import cm\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Model\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import keras\n",
    "import h5py\n",
    "import numpy as np\n",
    "from keras import regularizers\n",
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras import optimizers\n",
    "from keras.utils import to_categorical, plot_model\n",
    "from keras.layers import Dense, Input, Conv2D, Flatten, MaxPooling2D, Activation\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.optimizers import Adam\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.models import load_model\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "from keras.models import load_model\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.load('x_train_64_norm.npy')\n",
    "y_train = np.load('y_train_64.npy')\n",
    "x_test = np.load('x_test_64_norm.npy')\n",
    "y_test = np.load('y_test_64.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_dims(val):\n",
    "    val_exp = np.expand_dims(val, axis=4)\n",
    "    return val_exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = expand_dims(x_train)\n",
    "#x_test = expand_dims(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0825 23:08:50.210763  6452 deprecation_wrapper.py:119] From C:\\ProgramData\\Anaconda3\\envs\\clef\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:58: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0825 23:08:50.213761  6452 deprecation_wrapper.py:119] From C:\\ProgramData\\Anaconda3\\envs\\clef\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:442: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0825 23:08:50.218759  6452 deprecation_wrapper.py:119] From C:\\ProgramData\\Anaconda3\\envs\\clef\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3543: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0825 23:08:50.653494  6452 deprecation.py:506] From C:\\ProgramData\\Anaconda3\\envs\\clef\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1205: calling reduce_prod_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "W0825 23:08:50.688472  6452 deprecation.py:506] From C:\\ProgramData\\Anaconda3\\envs\\clef\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:2888: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W0825 23:08:50.787430  6452 deprecation_wrapper.py:119] From C:\\ProgramData\\Anaconda3\\envs\\clef\\lib\\site-packages\\keras\\optimizers.py:711: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 128, 128, 64, 1)   0         \n",
      "_________________________________________________________________\n",
      "conv3d_1 (Conv3D)            (None, 126, 126, 62, 64)  1792      \n",
      "_________________________________________________________________\n",
      "max_pooling3d_1 (MaxPooling3 (None, 63, 63, 31, 64)    0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 63, 63, 31, 64)    256       \n",
      "_________________________________________________________________\n",
      "conv3d_3 (Conv3D)            (None, 61, 61, 29, 64)    110656    \n",
      "_________________________________________________________________\n",
      "max_pooling3d_3 (MaxPooling3 (None, 30, 30, 14, 64)    0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 30, 30, 14, 64)    256       \n",
      "_________________________________________________________________\n",
      "conv3d_4 (Conv3D)            (None, 28, 28, 12, 128)   221312    \n",
      "_________________________________________________________________\n",
      "max_pooling3d_4 (MaxPooling3 (None, 14, 14, 6, 128)    0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 14, 14, 6, 128)    512       \n",
      "_________________________________________________________________\n",
      "conv3d_5 (Conv3D)            (None, 12, 12, 4, 256)    884992    \n",
      "_________________________________________________________________\n",
      "max_pooling3d_5 (MaxPooling3 (None, 6, 6, 2, 256)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 6, 6, 2, 256)      1024      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 18432)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               9437696   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 1026      \n",
      "=================================================================\n",
      "Total params: 10,659,522\n",
      "Trainable params: 10,658,498\n",
      "Non-trainable params: 1,024\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def m_naive():\n",
    "    \n",
    "    filter_size = 32\n",
    "    input_layer = Input((128, 128, 64, 1)) # 1 is just dummy dimension good for nothing \n",
    "    \n",
    "    conv_layer1 = Conv3D(filters=64, kernel_size=(3, 3, 3), activation='relu')(input_layer)\n",
    "    pooling_layer1 = MaxPool3D(pool_size=(2, 2, 2))(conv_layer1)\n",
    "\n",
    "    pooling_layer1 = BatchNormalization()(pooling_layer1)  \n",
    "    conv_layer2 = Conv3D(filters=64, kernel_size=(3, 3, 3), activation='relu')(pooling_layer1)\n",
    "    pooling_layer2 = MaxPool3D(pool_size=(2, 2, 2))(conv_layer2)\n",
    "    pooling_layer2 = BatchNormalization()(pooling_layer2)\n",
    "    conv_layer3 = Conv3D(filters=64, kernel_size=(3, 3, 3), activation='relu')(pooling_layer1)\n",
    "    pooling_layer3 = MaxPool3D(pool_size=(2, 2, 2))(conv_layer3)\n",
    "    pooling_layer3 = BatchNormalization()(pooling_layer3)\n",
    "    conv_layer4 = Conv3D(filters=128, kernel_size=(3, 3, 3), activation='relu')(pooling_layer3)\n",
    "    pooling_layer4 = MaxPool3D(pool_size=(2, 2, 2))(conv_layer4)\n",
    "    pooling_layer4 = BatchNormalization()(pooling_layer4)\n",
    "    conv_layer5 = Conv3D(filters=256, kernel_size=(3, 3, 3), activation='relu')(pooling_layer4)\n",
    "    pooling_layer5 = MaxPool3D(pool_size=(2, 2, 2))(conv_layer5)\n",
    "    \n",
    "    pooling_layer9 = BatchNormalization()(pooling_layer5)\n",
    "    flatten_layer = Flatten()(pooling_layer9)\n",
    "\n",
    "    #dense_layer1 = Dense(units=1028, activation='relu')(flatten_layer)\n",
    "    #dense_layer1 = Dropout(0.4)(dense_layer1)\n",
    "    \n",
    "    \n",
    "    #dense_layer2 = Dense(units=1028, activation='relu')(flatten_layer)\n",
    "    #dense_layer2 = Dropout(0.4)(dense_layer2)\n",
    "    \n",
    "    dense_layer3 = Dense(units=512, activation='relu')(flatten_layer)\n",
    "    dense_layer3 = Dropout(0.4)(dense_layer3)\n",
    "\n",
    "    dense_layer4 = Dense(units=256, activation='relu')(dense_layer3)\n",
    "    dense_layer4 = Dropout(0.4)(dense_layer3)\n",
    "  \n",
    "    output_layer = Dense(units=2, activation='softmax')(dense_layer4)\n",
    "\n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "    model.compile(loss='mae', optimizer=SGD(lr=1e-06, momentum=0.99, decay=0.0, nesterov=False), metrics=['acc']) # # optimizers.SGD(lr=1e-4, momentum=0.9)\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = None\n",
    "model = m_naive()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0825 23:08:52.823502  6452 deprecation_wrapper.py:119] From C:\\ProgramData\\Anaconda3\\envs\\clef\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:899: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "W0825 23:08:52.826485  6452 deprecation.py:506] From C:\\ProgramData\\Anaconda3\\envs\\clef\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:625: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0825 23:08:52.927442  6452 deprecation_wrapper.py:119] From C:\\ProgramData\\Anaconda3\\envs\\clef\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:886: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "218/218 [==============================] - 79s - loss: 0.4955 - acc: 0.4954    \n",
      "Epoch 2/200\n",
      "218/218 [==============================] - 68s - loss: 0.4990 - acc: 0.4862    \n",
      "Epoch 3/200\n",
      "218/218 [==============================] - 74s - loss: 0.4873 - acc: 0.5138    \n",
      "Epoch 4/200\n",
      "218/218 [==============================] - 74s - loss: 0.4631 - acc: 0.5734    \n",
      "Epoch 5/200\n",
      "218/218 [==============================] - 75s - loss: 0.4485 - acc: 0.5596    \n",
      "Epoch 6/200\n",
      "218/218 [==============================] - 78s - loss: 0.4423 - acc: 0.5917    \n",
      "Epoch 7/200\n",
      "218/218 [==============================] - 78s - loss: 0.4255 - acc: 0.6468    \n",
      "Epoch 8/200\n",
      "218/218 [==============================] - 78s - loss: 0.4318 - acc: 0.5872    \n",
      "Epoch 9/200\n",
      "218/218 [==============================] - 79s - loss: 0.3704 - acc: 0.7156    \n",
      "Epoch 10/200\n",
      "218/218 [==============================] - 79s - loss: 0.4098 - acc: 0.6330    \n",
      "Epoch 11/200\n",
      "218/218 [==============================] - 79s - loss: 0.3985 - acc: 0.6468    \n",
      "Epoch 12/200\n",
      "218/218 [==============================] - 79s - loss: 0.3588 - acc: 0.7064    \n",
      "Epoch 13/200\n",
      "218/218 [==============================] - 79s - loss: 0.3651 - acc: 0.7110    \n",
      "Epoch 14/200\n",
      "218/218 [==============================] - 80s - loss: 0.3680 - acc: 0.6468    \n",
      "Epoch 15/200\n",
      "218/218 [==============================] - 82s - loss: 0.3471 - acc: 0.7294    \n",
      "Epoch 16/200\n",
      "218/218 [==============================] - 82s - loss: 0.3319 - acc: 0.7431    \n",
      "Epoch 17/200\n",
      "218/218 [==============================] - 81s - loss: 0.3144 - acc: 0.7615    \n",
      "Epoch 18/200\n",
      "218/218 [==============================] - 81s - loss: 0.3064 - acc: 0.7615    \n",
      "Epoch 19/200\n",
      "218/218 [==============================] - 82s - loss: 0.3019 - acc: 0.7890    \n",
      "Epoch 20/200\n",
      "218/218 [==============================] - 81s - loss: 0.2801 - acc: 0.8119    \n",
      "Epoch 21/200\n",
      "218/218 [==============================] - 82s - loss: 0.2643 - acc: 0.8165    \n",
      "Epoch 22/200\n",
      "218/218 [==============================] - 82s - loss: 0.2690 - acc: 0.8211    \n",
      "Epoch 23/200\n",
      "218/218 [==============================] - 81s - loss: 0.2807 - acc: 0.7936    \n",
      "Epoch 24/200\n",
      "218/218 [==============================] - 82s - loss: 0.2642 - acc: 0.8440    \n",
      "Epoch 25/200\n",
      "218/218 [==============================] - 82s - loss: 0.2374 - acc: 0.8486    \n",
      "Epoch 26/200\n",
      "218/218 [==============================] - 81s - loss: 0.2441 - acc: 0.8257    \n",
      "Epoch 27/200\n",
      "218/218 [==============================] - 81s - loss: 0.2340 - acc: 0.8486    \n",
      "Epoch 28/200\n",
      "218/218 [==============================] - 81s - loss: 0.2426 - acc: 0.8349    \n",
      "Epoch 29/200\n",
      "218/218 [==============================] - 82s - loss: 0.2136 - acc: 0.8807    \n",
      "Epoch 30/200\n",
      "218/218 [==============================] - 82s - loss: 0.1925 - acc: 0.9174    \n",
      "Epoch 31/200\n",
      "218/218 [==============================] - 81s - loss: 0.1917 - acc: 0.8991    \n",
      "Epoch 32/200\n",
      "218/218 [==============================] - 81s - loss: 0.1770 - acc: 0.8945    \n",
      "Epoch 33/200\n",
      "218/218 [==============================] - 81s - loss: 0.1848 - acc: 0.8991    \n",
      "Epoch 34/200\n",
      "218/218 [==============================] - 81s - loss: 0.1874 - acc: 0.8899    \n",
      "Epoch 35/200\n",
      "218/218 [==============================] - 81s - loss: 0.1628 - acc: 0.9174    \n",
      "Epoch 36/200\n",
      "218/218 [==============================] - 82s - loss: 0.1502 - acc: 0.9358    \n",
      "Epoch 37/200\n",
      "218/218 [==============================] - 81s - loss: 0.1665 - acc: 0.9220    \n",
      "Epoch 38/200\n",
      "218/218 [==============================] - 81s - loss: 0.1758 - acc: 0.9358    \n",
      "Epoch 39/200\n",
      "218/218 [==============================] - 82s - loss: 0.1378 - acc: 0.9679    \n",
      "Epoch 40/200\n",
      "218/218 [==============================] - 81s - loss: 0.1358 - acc: 0.9541    \n",
      "Epoch 41/200\n",
      "218/218 [==============================] - 83s - loss: 0.1261 - acc: 0.9725    \n",
      "Epoch 42/200\n",
      "218/218 [==============================] - 81s - loss: 0.1242 - acc: 0.9495    \n",
      "Epoch 43/200\n",
      "218/218 [==============================] - 81s - loss: 0.1203 - acc: 0.9633    \n",
      "Epoch 44/200\n",
      "218/218 [==============================] - 82s - loss: 0.1204 - acc: 0.9771    \n",
      "Epoch 45/200\n",
      "218/218 [==============================] - 81s - loss: 0.1198 - acc: 0.9541    \n",
      "Epoch 46/200\n",
      "218/218 [==============================] - 81s - loss: 0.1135 - acc: 0.9679    \n",
      "Epoch 47/200\n",
      "218/218 [==============================] - 82s - loss: 0.1129 - acc: 0.9541    \n",
      "Epoch 48/200\n",
      "218/218 [==============================] - 81s - loss: 0.1084 - acc: 0.9725    \n",
      "Epoch 49/200\n",
      "218/218 [==============================] - 81s - loss: 0.1023 - acc: 0.9587    \n",
      "Epoch 50/200\n",
      "218/218 [==============================] - 82s - loss: 0.1097 - acc: 0.9587    \n",
      "Epoch 51/200\n",
      "218/218 [==============================] - 83s - loss: 0.0868 - acc: 0.9908    \n",
      "Epoch 52/200\n",
      "218/218 [==============================] - 81s - loss: 0.1038 - acc: 0.9725    \n",
      "Epoch 53/200\n",
      "218/218 [==============================] - 81s - loss: 0.0867 - acc: 0.9817    \n",
      "Epoch 54/200\n",
      "218/218 [==============================] - 81s - loss: 0.0930 - acc: 0.9725    \n",
      "Epoch 55/200\n",
      "218/218 [==============================] - 81s - loss: 0.0889 - acc: 0.9862    \n",
      "Epoch 56/200\n",
      "218/218 [==============================] - 81s - loss: 0.0823 - acc: 0.9862    \n",
      "Epoch 57/200\n",
      "218/218 [==============================] - 82s - loss: 0.0855 - acc: 0.9954    \n",
      "Epoch 58/200\n",
      "218/218 [==============================] - 80s - loss: 0.0695 - acc: 0.9954    \n",
      "Epoch 59/200\n",
      "218/218 [==============================] - 81s - loss: 0.0709 - acc: 0.9862    \n",
      "Epoch 60/200\n",
      "218/218 [==============================] - 81s - loss: 0.0637 - acc: 0.9954    \n",
      "Epoch 61/200\n",
      "218/218 [==============================] - 81s - loss: 0.0756 - acc: 0.9862    \n",
      "Epoch 62/200\n",
      "218/218 [==============================] - 81s - loss: 0.0636 - acc: 0.9954    \n",
      "Epoch 63/200\n",
      "218/218 [==============================] - 81s - loss: 0.0679 - acc: 0.9908    \n",
      "Epoch 64/200\n",
      "218/218 [==============================] - 81s - loss: 0.0756 - acc: 0.9862    \n",
      "Epoch 65/200\n",
      "218/218 [==============================] - 81s - loss: 0.0678 - acc: 0.9725    \n",
      "Epoch 66/200\n",
      "218/218 [==============================] - 81s - loss: 0.0475 - acc: 0.9954    \n",
      "Epoch 67/200\n",
      "218/218 [==============================] - 81s - loss: 0.0628 - acc: 0.9908    \n",
      "Epoch 68/200\n",
      "218/218 [==============================] - 81s - loss: 0.0652 - acc: 0.9817    \n",
      "Epoch 69/200\n",
      "218/218 [==============================] - 82s - loss: 0.0571 - acc: 1.0000    \n",
      "Epoch 70/200\n",
      "218/218 [==============================] - 80s - loss: 0.0550 - acc: 0.9862    \n",
      "Epoch 71/200\n",
      "218/218 [==============================] - 81s - loss: 0.0620 - acc: 0.9908    \n",
      "Epoch 72/200\n",
      "218/218 [==============================] - 82s - loss: 0.0553 - acc: 0.9954    \n",
      "Epoch 73/200\n",
      "218/218 [==============================] - 81s - loss: 0.0466 - acc: 0.9908    \n",
      "Epoch 74/200\n",
      "218/218 [==============================] - 82s - loss: 0.0405 - acc: 0.9954    \n",
      "Epoch 75/200\n",
      "218/218 [==============================] - 81s - loss: 0.0409 - acc: 0.9954    \n",
      "Epoch 76/200\n",
      "218/218 [==============================] - 82s - loss: 0.0514 - acc: 0.9908    \n",
      "Epoch 77/200\n",
      "218/218 [==============================] - 82s - loss: 0.0440 - acc: 0.9954    \n",
      "Epoch 78/200\n",
      "218/218 [==============================] - 81s - loss: 0.0421 - acc: 1.0000    \n",
      "Epoch 79/200\n",
      "218/218 [==============================] - 81s - loss: 0.0589 - acc: 0.9908    \n",
      "Epoch 80/200\n",
      "218/218 [==============================] - 81s - loss: 0.0387 - acc: 0.9954    \n",
      "Epoch 81/200\n",
      "218/218 [==============================] - 81s - loss: 0.0438 - acc: 1.0000    \n",
      "Epoch 82/200\n",
      "218/218 [==============================] - 81s - loss: 0.0440 - acc: 0.9954    \n",
      "Epoch 83/200\n",
      "218/218 [==============================] - 82s - loss: 0.0390 - acc: 0.9954    \n",
      "Epoch 84/200\n",
      "218/218 [==============================] - 82s - loss: 0.0378 - acc: 0.9954    \n",
      "Epoch 85/200\n",
      "218/218 [==============================] - 81s - loss: 0.0425 - acc: 1.0000    \n",
      "Epoch 86/200\n",
      "218/218 [==============================] - 82s - loss: 0.0366 - acc: 1.0000    \n",
      "Epoch 87/200\n",
      "218/218 [==============================] - 82s - loss: 0.0450 - acc: 1.0000    \n",
      "Epoch 88/200\n",
      "218/218 [==============================] - 82s - loss: 0.0314 - acc: 1.0000    \n",
      "Epoch 89/200\n",
      "218/218 [==============================] - 82s - loss: 0.0358 - acc: 0.9954    \n",
      "Epoch 90/200\n",
      "218/218 [==============================] - 82s - loss: 0.0322 - acc: 0.9954    \n",
      "Epoch 91/200\n",
      "218/218 [==============================] - 82s - loss: 0.0305 - acc: 1.0000    \n",
      "Epoch 92/200\n",
      "218/218 [==============================] - 81s - loss: 0.0307 - acc: 1.0000    \n",
      "Epoch 93/200\n",
      "218/218 [==============================] - 81s - loss: 0.0291 - acc: 1.0000    \n",
      "Epoch 94/200\n",
      "218/218 [==============================] - 82s - loss: 0.0314 - acc: 1.0000    \n",
      "Epoch 95/200\n",
      "218/218 [==============================] - 81s - loss: 0.0262 - acc: 1.0000    \n",
      "Epoch 96/200\n",
      "218/218 [==============================] - 81s - loss: 0.0370 - acc: 1.0000    \n",
      "Epoch 97/200\n",
      "218/218 [==============================] - 81s - loss: 0.0302 - acc: 1.0000    \n",
      "Epoch 98/200\n",
      "218/218 [==============================] - 82s - loss: 0.0350 - acc: 0.9862    \n",
      "Epoch 99/200\n",
      "218/218 [==============================] - 81s - loss: 0.0233 - acc: 1.0000    \n",
      "Epoch 100/200\n",
      "218/218 [==============================] - 81s - loss: 0.0260 - acc: 1.0000    \n",
      "Epoch 101/200\n",
      "218/218 [==============================] - 81s - loss: 0.0275 - acc: 1.0000    \n",
      "Epoch 102/200\n",
      "218/218 [==============================] - 82s - loss: 0.0298 - acc: 0.9954    \n",
      "Epoch 103/200\n",
      "218/218 [==============================] - 81s - loss: 0.0291 - acc: 1.0000    \n",
      "Epoch 104/200\n",
      "218/218 [==============================] - 81s - loss: 0.0246 - acc: 1.0000    \n",
      "Epoch 105/200\n",
      "218/218 [==============================] - 82s - loss: 0.0287 - acc: 1.0000    \n",
      "Epoch 106/200\n",
      "218/218 [==============================] - 81s - loss: 0.0308 - acc: 1.0000    \n",
      "Epoch 107/200\n",
      "218/218 [==============================] - 81s - loss: 0.0256 - acc: 1.0000    \n",
      "Epoch 108/200\n",
      "218/218 [==============================] - 81s - loss: 0.0220 - acc: 1.0000    \n",
      "Epoch 109/200\n",
      "218/218 [==============================] - 81s - loss: 0.0257 - acc: 1.0000    \n",
      "Epoch 110/200\n",
      "218/218 [==============================] - 81s - loss: 0.0234 - acc: 1.0000    \n",
      "Epoch 111/200\n",
      "218/218 [==============================] - 81s - loss: 0.0234 - acc: 1.0000    \n",
      "Epoch 112/200\n",
      "218/218 [==============================] - 81s - loss: 0.0249 - acc: 1.0000    \n",
      "Epoch 113/200\n",
      "218/218 [==============================] - 82s - loss: 0.0224 - acc: 1.0000    \n",
      "Epoch 114/200\n",
      "218/218 [==============================] - 82s - loss: 0.0266 - acc: 1.0000    \n",
      "Epoch 115/200\n",
      "218/218 [==============================] - 81s - loss: 0.0202 - acc: 1.0000    \n",
      "Epoch 116/200\n",
      "218/218 [==============================] - 81s - loss: 0.0217 - acc: 1.0000    \n",
      "Epoch 117/200\n",
      "218/218 [==============================] - 81s - loss: 0.0221 - acc: 1.0000    \n",
      "Epoch 118/200\n",
      "218/218 [==============================] - 81s - loss: 0.0226 - acc: 1.0000    \n",
      "Epoch 119/200\n",
      "218/218 [==============================] - 81s - loss: 0.0251 - acc: 1.0000    \n",
      "Epoch 120/200\n",
      "218/218 [==============================] - 81s - loss: 0.0198 - acc: 1.0000    \n",
      "Epoch 121/200\n",
      "218/218 [==============================] - 81s - loss: 0.0202 - acc: 1.0000    \n",
      "Epoch 122/200\n",
      "218/218 [==============================] - 81s - loss: 0.0238 - acc: 1.0000    \n",
      "Epoch 123/200\n",
      "218/218 [==============================] - 81s - loss: 0.0195 - acc: 1.0000    \n",
      "Epoch 124/200\n",
      "218/218 [==============================] - 81s - loss: 0.0196 - acc: 1.0000    \n",
      "Epoch 125/200\n",
      "218/218 [==============================] - 82s - loss: 0.0225 - acc: 1.0000    \n",
      "Epoch 126/200\n",
      "218/218 [==============================] - 81s - loss: 0.0195 - acc: 0.9954    \n",
      "Epoch 127/200\n",
      "218/218 [==============================] - 81s - loss: 0.0193 - acc: 0.9954    \n",
      "Epoch 128/200\n",
      "218/218 [==============================] - 81s - loss: 0.0162 - acc: 1.0000    \n",
      "Epoch 129/200\n",
      "218/218 [==============================] - 81s - loss: 0.0171 - acc: 1.0000    \n",
      "Epoch 130/200\n",
      "218/218 [==============================] - 81s - loss: 0.0194 - acc: 1.0000    \n",
      "Epoch 131/200\n",
      "218/218 [==============================] - 81s - loss: 0.0230 - acc: 1.0000    \n",
      "Epoch 132/200\n",
      "218/218 [==============================] - 81s - loss: 0.0185 - acc: 1.0000    \n",
      "Epoch 133/200\n",
      "218/218 [==============================] - 81s - loss: 0.0196 - acc: 1.0000    \n",
      "Epoch 134/200\n",
      "218/218 [==============================] - 82s - loss: 0.0156 - acc: 1.0000    \n",
      "Epoch 135/200\n",
      "218/218 [==============================] - 82s - loss: 0.0169 - acc: 1.0000    \n",
      "Epoch 136/200\n",
      "218/218 [==============================] - 81s - loss: 0.0169 - acc: 1.0000    \n",
      "Epoch 137/200\n",
      "218/218 [==============================] - 81s - loss: 0.0142 - acc: 1.0000    \n",
      "Epoch 138/200\n",
      "218/218 [==============================] - 82s - loss: 0.0166 - acc: 1.0000    \n",
      "Epoch 139/200\n",
      "218/218 [==============================] - 82s - loss: 0.0156 - acc: 1.0000    \n",
      "Epoch 140/200\n",
      "218/218 [==============================] - 81s - loss: 0.0142 - acc: 1.0000    \n",
      "Epoch 141/200\n",
      "218/218 [==============================] - 81s - loss: 0.0115 - acc: 1.0000    \n",
      "Epoch 142/200\n",
      "218/218 [==============================] - 81s - loss: 0.0134 - acc: 1.0000    \n",
      "Epoch 143/200\n",
      "218/218 [==============================] - 81s - loss: 0.0167 - acc: 0.9954    \n",
      "Epoch 144/200\n",
      "218/218 [==============================] - 81s - loss: 0.0149 - acc: 1.0000    \n",
      "Epoch 145/200\n",
      "218/218 [==============================] - 81s - loss: 0.0172 - acc: 1.0000    \n",
      "Epoch 146/200\n",
      "218/218 [==============================] - 81s - loss: 0.0154 - acc: 0.9954    \n",
      "Epoch 147/200\n",
      "218/218 [==============================] - 81s - loss: 0.0140 - acc: 1.0000    \n",
      "Epoch 148/200\n",
      "218/218 [==============================] - 81s - loss: 0.0156 - acc: 1.0000    \n",
      "Epoch 149/200\n",
      "218/218 [==============================] - 81s - loss: 0.0142 - acc: 1.0000    \n",
      "Epoch 150/200\n",
      "218/218 [==============================] - 81s - loss: 0.0113 - acc: 1.0000    \n",
      "Epoch 151/200\n",
      "218/218 [==============================] - 81s - loss: 0.0164 - acc: 1.0000    \n",
      "Epoch 152/200\n",
      "218/218 [==============================] - 81s - loss: 0.0121 - acc: 1.0000    \n",
      "Epoch 153/200\n",
      "218/218 [==============================] - 81s - loss: 0.0124 - acc: 1.0000    \n",
      "Epoch 154/200\n",
      "218/218 [==============================] - 82s - loss: 0.0170 - acc: 1.0000    \n",
      "Epoch 155/200\n",
      "218/218 [==============================] - 81s - loss: 0.0165 - acc: 1.0000    \n",
      "Epoch 156/200\n",
      "218/218 [==============================] - 81s - loss: 0.0107 - acc: 1.0000    \n",
      "Epoch 157/200\n",
      "218/218 [==============================] - 82s - loss: 0.0103 - acc: 1.0000    \n",
      "Epoch 158/200\n",
      "218/218 [==============================] - 82s - loss: 0.0099 - acc: 1.0000    \n",
      "Epoch 159/200\n",
      "218/218 [==============================] - 81s - loss: 0.0139 - acc: 1.0000    \n",
      "Epoch 160/200\n",
      "218/218 [==============================] - 81s - loss: 0.0153 - acc: 1.0000    \n",
      "Epoch 161/200\n",
      "218/218 [==============================] - 81s - loss: 0.0122 - acc: 1.0000    \n",
      "Epoch 162/200\n",
      "218/218 [==============================] - 81s - loss: 0.0116 - acc: 1.0000    \n",
      "Epoch 163/200\n",
      "218/218 [==============================] - 81s - loss: 0.0098 - acc: 1.0000    \n",
      "Epoch 164/200\n",
      "218/218 [==============================] - 81s - loss: 0.0130 - acc: 1.0000    \n",
      "Epoch 165/200\n",
      "218/218 [==============================] - 79s - loss: 0.0090 - acc: 1.0000    \n",
      "Epoch 166/200\n",
      "218/218 [==============================] - 79s - loss: 0.0143 - acc: 1.0000    \n",
      "Epoch 167/200\n",
      "218/218 [==============================] - 79s - loss: 0.0132 - acc: 1.0000    \n",
      "Epoch 168/200\n",
      "218/218 [==============================] - 79s - loss: 0.0106 - acc: 1.0000    \n",
      "Epoch 169/200\n",
      "218/218 [==============================] - 79s - loss: 0.0109 - acc: 1.0000    \n",
      "Epoch 170/200\n",
      "218/218 [==============================] - 79s - loss: 0.0112 - acc: 1.0000    \n",
      "Epoch 171/200\n",
      "218/218 [==============================] - 79s - loss: 0.0096 - acc: 1.0000    \n",
      "Epoch 172/200\n",
      "218/218 [==============================] - 79s - loss: 0.0096 - acc: 1.0000    \n",
      "Epoch 173/200\n",
      "218/218 [==============================] - 79s - loss: 0.0121 - acc: 0.9954    \n",
      "Epoch 174/200\n",
      "218/218 [==============================] - 79s - loss: 0.0132 - acc: 1.0000    \n",
      "Epoch 175/200\n",
      "218/218 [==============================] - 79s - loss: 0.0112 - acc: 1.0000    \n",
      "Epoch 176/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "218/218 [==============================] - 79s - loss: 0.0110 - acc: 1.0000    \n",
      "Epoch 177/200\n",
      "218/218 [==============================] - 79s - loss: 0.0104 - acc: 1.0000    \n",
      "Epoch 178/200\n",
      "218/218 [==============================] - 79s - loss: 0.0119 - acc: 1.0000    \n",
      "Epoch 179/200\n",
      "218/218 [==============================] - 79s - loss: 0.0103 - acc: 1.0000    \n",
      "Epoch 180/200\n",
      "218/218 [==============================] - 79s - loss: 0.0106 - acc: 1.0000    \n",
      "Epoch 181/200\n",
      "218/218 [==============================] - 78s - loss: 0.0150 - acc: 1.0000    \n",
      "Epoch 182/200\n",
      "218/218 [==============================] - 78s - loss: 0.0128 - acc: 1.0000    \n",
      "Epoch 183/200\n",
      "218/218 [==============================] - 78s - loss: 0.0118 - acc: 0.9954    \n",
      "Epoch 184/200\n",
      "218/218 [==============================] - 78s - loss: 0.0132 - acc: 1.0000    \n",
      "Epoch 185/200\n",
      "218/218 [==============================] - 78s - loss: 0.0093 - acc: 1.0000    \n",
      "Epoch 186/200\n",
      "218/218 [==============================] - 78s - loss: 0.0113 - acc: 1.0000    \n",
      "Epoch 187/200\n",
      "218/218 [==============================] - 78s - loss: 0.0078 - acc: 1.0000    \n",
      "Epoch 188/200\n",
      "218/218 [==============================] - 78s - loss: 0.0088 - acc: 1.0000    \n",
      "Epoch 189/200\n",
      "218/218 [==============================] - 78s - loss: 0.0156 - acc: 1.0000    \n",
      "Epoch 190/200\n",
      "218/218 [==============================] - 78s - loss: 0.0105 - acc: 1.0000    \n",
      "Epoch 191/200\n",
      "218/218 [==============================] - 78s - loss: 0.0118 - acc: 1.0000    \n",
      "Epoch 192/200\n",
      "218/218 [==============================] - 78s - loss: 0.0110 - acc: 1.0000    \n",
      "Epoch 193/200\n",
      "218/218 [==============================] - 78s - loss: 0.0098 - acc: 1.0000    \n",
      "Epoch 194/200\n",
      "218/218 [==============================] - 78s - loss: 0.0086 - acc: 1.0000    \n",
      "Epoch 195/200\n",
      "218/218 [==============================] - 78s - loss: 0.0117 - acc: 1.0000    \n",
      "Epoch 196/200\n",
      "218/218 [==============================] - 78s - loss: 0.0095 - acc: 1.0000    \n",
      "Epoch 197/200\n",
      "218/218 [==============================] - 78s - loss: 0.0079 - acc: 1.0000    \n",
      "Epoch 198/200\n",
      "218/218 [==============================] - 78s - loss: 0.0105 - acc: 1.0000    \n",
      "Epoch 199/200\n",
      "218/218 [==============================] - 78s - loss: 0.0097 - acc: 1.0000    \n",
      "Epoch 200/200\n",
      "218/218 [==============================] - 78s - loss: 0.0097 - acc: 1.0000    \n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# set the learning rate\n",
    "#K.set_value(model.optimizer.lr, 0.01) \n",
    "\n",
    "h=model.fit(x=x_train,     \n",
    "            y=y_train, \n",
    "            batch_size=2, \n",
    "            epochs=200, \n",
    "            verbose=1, \n",
    "            #validation_data = (x_test,y_test),\n",
    "            #validation_split = 0.1,\n",
    "            shuffle=True,\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss_accu(history):\n",
    "    loss = history.history['loss']\n",
    "    epochs = range(len(loss))\n",
    "    plt.plot(epochs, loss, 'g')\n",
    "    plt.title('Training loss')\n",
    "    plt.legend(['train'], loc='upper right')\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "    loss = history.history['acc']\n",
    "    epochs = range(len(loss))\n",
    "    plt.plot(epochs, loss, 'r')\n",
    "    plt.title('Training accuracy')\n",
    "    plt.legend(['train'], loc='lower right')\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAgAElEQVR4nO3deVyVZf7/8dcHBJRFVJAtRXBJEbfE1FxStBTL3VyysZqmsZoxq6n5fm361jRNts6vmvaasXRMs8UcrUybUkot18R9Q0XFFTERBGS7fn+cA4MGcg7CuQ+Hz/Px4OG57/u6z3mf+xw/XFz3JsYYlFJK1X1eVgdQSilVM7SgK6WUh9CCrpRSHkILulJKeQgt6Eop5SG0oCullIfQgq48hoh4i0iOiETXZNtq5HhaRGbX9PMqVZUGVgdQ9ZeI5JSb9AcuAMX26XuMMfOceT5jTDEQWNNtlaortKAryxhjygqqiKQBdxtjvqmsvYg0MMYUuSKbUnWRDrkot2UfuvhIRD4UkWzgVyJynYisFZGzInJcRF4VER97+wYiYkQkxj79gX35VyKSLSI/ikiss23ty4eJyF4RyRKR10RkjYjc6eD7GC0iO+yZV4hI+3LL/iQix0TknIjsFpGB9vm9ReQn+/yTIvJiDWxS5eG0oCt3NwaYDwQDHwFFwANAKNAXSALuucz6k4HHgWbAYeCvzrYVkTDgY+CP9tc9CPR0JLyIxAEfAPcDzYFvgM9FxEdE4u3ZuxtjGgPD7K8L8Brwon1+W+BTR15P1W9a0JW7W22M+dwYU2KMyTPGbDDGrDPGFBljDgDvAgMus/6nxpiNxphCYB7QrRpthwMpxpjF9mUvA6cdzD8JWGKMWWFf9zmgMdAL2y+nhkC8fTjpoP09ARQC7UQkxBiTbYxZ5+DrqXpMC7pyd0fKT4hIBxH5UkROiMg54ClsvebKnCj3OJfL7witrG1U+RzGdkW7dAeyl657qNy6JfZ1rzLG7AEexvYeTtmHliLsTX8NdAT2iMh6EbnJwddT9ZgWdOXuLr0c6DvAdqCtfTjiCUBqOcNxoEXphIgIcJWD6x4DWpVb18v+XEcBjDEfGGP6ArGAN/Csff4eY8wkIAz4f8BCEWl45W9FeTIt6KquCQKygPP28enLjZ/XlC+A7iIyQkQaYBvDb+7guh8DI0VkoH3n7R+BbGCdiMSJSKKI+AF59p9iABGZIiKh9h59FrZfbCU1+7aUp9GCruqah4E7sBXFd7DtKK1VxpiTwETgJSATaANsxnbcfFXr7sCW9y0gA9tO3JH28XQ/4AVs4/EngKbA/9lXvQnYZT+652/ARGNMQQ2+LeWBRG9woZRzRMQb21DKLcaYVVbnUaqU9tCVcoCIJIlIsH145HFsR6istziWUhfRgq6UY/oBB7ANjyQBo40xVQ65KOVKOuSilFIeQnvoSinlISy7OFdoaKiJiYmp1rrnz58nICCgZgPVEHfNprmco7mc567ZPC3Xpk2bThtjKj5s1hhjyU9CQoKprpUrV1Z73drmrtk0l3M0l/PcNZun5QI2mkrqqg65KKWUh9CCrpRSHkILulJKeQi9Y5FSqk4pLCwkPT2d/Px8h9oHBweza9euWk7lvKpyNWzYkBYtWuDj4+Pwc2pBV0rVKenp6QQFBRETE4PtwpeXl52dTVBQkAuSOedyuYwxZGZmkp6eTmxsbIVtKuLQkIv9tOc9IpIqIjMqWH6niGSISIr9526HEyillBPy8/MJCQlxqJjXVSJCSEiIw3+FlKqyh26/ENEbwI3YLsy/QUSWGGN2XtL0I2PMNKdeXSmlqsGTi3mp6rxHR3roPYFUY8wBY7t85wJglNOvVIOMMXy681MO/nzQyhhKKeVWqryWi4jcAiQZY+62T08BepXvjdvvfv4stus97wUeMsYcqeC5pgJTAcLDwxMWLFjgdOASU8LLu17mi4wv6BPSh5mdZjr9HLUpJyeHwMDL3eXMGprLOZrLea7KFhwcTNu2bR1uX1xcjLe3d429/tmzZ/nkk0/47W9/69R648aNY9asWTRp0sThXKmpqWRlZV00LzExcZMxpkeFK1R2xlHpDzAe+Ge56SnAa5e0CQH87I/vBVZU9bzVPVP0iRVPGJ7ERL8cbfz+6mfO5Z+r1vPUFk87K622aS7nuGsuY1yXbefOnU61P3euZmvEwYMHTXx8/C/mFxUVOfU8juSq6L1yhWeKpgMty023wHZx//K/FDLNfy8l+g8gwYHnrZbf9/w9D7V7iA/GfMCF4gss3be0tl5KKaV+YcaMGezfv59u3bpx7bXXkpiYyOTJk+ncuTMAo0ePJiEhgfj4eN59992y9WJiYjh9+jRpaWnExcVx//33Ex8fz5AhQ8jLy6uRbI4ctrgBaCcisdhubDsJmFy+gYhEGmOO2ydHArV20GdYQBgjo0bSp2UfwgPCWbhrIRM7Taytl1NKubEHlz1IyomUy7ZxdsilW0Q3Xkl6pdLlzz33HNu3byclJYXk5GRuvvlmtm/fXnZ44XvvvUezZs3Iy8vj2muvZdy4cYSEhFz0HPv27eOf//wns2fPZsKECSxcuJBf/epXDmesTJUF3RhTJCLTgOXY7kr+njFmh4g8ha3rvwSYLiIjsd3F5Qxw5xUnq4K3lzdjOoxh7ta55Bfl07CB3hBdKeV6PXv2vOhY8VdffZVFixYBcOTIEfbt2/eLgh4bG0uXLl0ASEhIIC0trUayOHRikTFmKbD0knlPlHv8KPBojSRywuDWg3l709vszNhJ98jurn55pZTFLteTLlXbJxaVvwRucnIy33zzDT/++CP+/v4MHDiwwmPJ/fz8yh57e3vX2JBLnb6WS1xoHAC7T++2OIlSqr4ICgoiOzu7wmVZWVk0bdoUf39/du/ezdq1a12arU6f+t+2WVu8xItdGe53nQallGcKCQmhb9++dOrUiUaNGhEeHl62LCkpibfffpsuXbrQvn17evfu7dJsdbqg+zXwo03TNuzO1B66Usp15s+fX+F8Pz8/vvrqqwqXlY6Th4aGsn379rJe/iOPPFJjuer0kAtAh9AOOuSilFJ4SEHfm7mXopIiq6MopZSl6nxBjwuNo6C4gLSzaVZHUUq5iKnikiWeoDrvsc4X9A6hHQA90kWp+qJhw4ZkZmZ6dFE39uuhN2zo3Pk1dXqnKPy3oO/K2MXwq4dbnEYpVdtatGhBeno6GRkZDrXPz893ujC6QlW5Su9Y5Iw6X9CbNmpKeEA4OzJ2WB1FKeUCPj4+Tt3FJzk5mWuuuaYWE1VPbeSq80MuAH1a9uG7Q99ZHUMppSzlEQV9UOwg0s6m6Q0vlFL1mscUdIAVB1dYnEQppazjEQU9LjSO8IBwVqRpQVdK1V8eUdBFhEGxg1hxcIVHH8qklFKX4xEFHWBw7GBO5JwgOS3Z6ihKKWUJjynot3a+lZgmMUz7ahoFxQVWx1FKKZfzmILu7+PPa8NeY2fGTl5d96rVcZRSyuU8pqADDL96OP2i+zF/W8WXtlRKKU/mUQUdIDEmkS0nt5BTkGN1FKWUcimPK+h9WvahxJSw/uh6q6MopZRL1flruVyqd4veCMKaw2to2rAp3l7edAnvYnUspZSqdR7XQ2/SsAnxYfF8ue9Lbph7Aw8se8DqSEop5RIeV9AB+rTow7qj6ziTd4bM3Eyr4yillEt4ZkFv2QcAHy8fzuaftTiNUkq5hseNoQPc0vEWMnIzSD2TqocwKqXqDY/soQf4BvBIn0eICooiuyBbbyCtlKoXPLKglwr2Cwbg3IVzFidRSqna59EFvUnDJgA6jq6Uqhe0oCullIeoFwU9Kz+L5LRkFu5caHEipZSqPfWioJ/NP8vMVTO5a8ld5BflW5xKKaVqh0MFXUSSRGSPiKSKyIzLtLtFRIyI9Ki5iNVXvqAfzz7OuQvn+Hr/1xanUkqp2lFlQRcRb+ANYBjQEbhVRDpW0C4ImA6sq+mQ1XVRQc85DsDHOz62MpJSStUaR3roPYFUY8wBY0wBsAAYVUG7vwIvAG4zphHkF4QgnDx/kjN5Z/AWbxbvWUxeYZ7V0ZRSqsZJVTdVFpFbgCRjzN326SlAL2PMtHJtrgH+zxgzTkSSgUeMMRsreK6pwFSA8PDwhAULFlQrdE5ODoGBgQ61Hb56ONc0uYbVmasZ0HwA32V8x7OdnqV3SO9qvXZNZnMlzeUczeU8d83mabkSExM3GWMqHNZ25NR/qWBe2W8BEfECXgburOqJjDHvAu8C9OjRwwwcONCBl/+l5ORkHF03NCWUDDIAmNJ7Ct99/h1BLYMY2LN6r12T2VxJczlHcznPXbPVp1yODLmkAy3LTbcAjpWbDgI6Ackikgb0Bpa4047R/T/vB6BzeGe8xKtsPF0ppTyJIwV9A9BORGJFxBeYBCwpXWiMyTLGhBpjYowxMcBaYGRFQy5WaNKwSdm1XFo0bkFYQBgnck5YnEoppWpelQXdGFMETAOWA7uAj40xO0TkKREZWdsBr1TpkS6CEBYQRmRgpPbQlVIeyaHL5xpjlgJLL5n3RCVtB155rJpTWtCbBzSngVcDIoMitYeulPJIHn2mKPz3iouRgZEARAREcDxbe+hKKc/j8QW9tIceERgBQGRQJCfPn6S4pNjKWEopVePqTUGPDLL30AMjKDElnM49bWUspZSqcfWnoNuHXEr/1R2jSilPU28KeumQS+m/umNUKeVp6k1BL+uh24dedMeoUsrTeHxB7xHVg9u73k5ibCJwcQ+9xJTw0o8vMeObSq8IrJRSdYZDx6HXZUF+QcwZPads2t/Hn8Z+jTmUdYgRH45g6b6lCMLj1z9OgG+AhUmVUurKeHwPvSKRgZHMTpnN0n1LGRc3DoNh+6ntVsdSSqkrUi8LekRgBBeKLzC6w2j+NuRvAGw5ucXiVEopdWXqZUFvGdyShg0a8vLQl2kV3IrGfo3ZckILulKqbquXBX3moJms+vUqYprEICJ0Ce/C1lNbrY6llFJXpF4W9OjgaHpE/fdy7V3CurD15FaqunuTUkq5s3pZ0C/VNaIr5y6c41DWIaujKKVUtWlBB7qEdwHQcXSlVJ2mBR3oHGa7Nd3GY25xkyWllKoWLehAgG8ACZEJfHfoO6ujKKVUtWlBtxsYM5B1R9eRW5hrdRSllKoWLeh2A2MGUlBcwNr0tVZHUUqpatGCbtcvuh9e4kVyWrLVUZRSqlq0oNs19mtMQmSCFnSlVJ2lBb2cAa0GsO7oOvKL8q2OopRSTtOCXs51La+joLiAlBMpVkdRSimnaUEvp3eL3gC6Y1QpVSdpQS8nKiiKlo1bakFXStVJWtAv0btFb9YdXWd1DKWUcpoW9Ev0uqoXaWfTOJFzwuooSinlFC3olygdR1+Xrr10pVTdogX9Et0ju+Pr7ctXqV9ZHUUppZyiBf0SjXwaMaXLFGanzNZhF6VUnaIFvQL/2/d/KSwp5JW1r1gdRSmlHOZQQReRJBHZIyKpIjKjguX3isg2EUkRkdUi0rHmo7pOu5B2jO84njc2vMG+zH1Wx1FKKYdUWdBFxBt4AxgGdARuraBgzzfGdDbGdANeAF6q8aQu9uzgZ/Hz9mP4h8P5Oe9nq+MopVSVHOmh9wRSjTEHjDEFwAJgVPkGxphz5SYDgDp/t+XYprEsmriIgz8fZOaqmVbHUUqpKklVd7oXkVuAJGPM3fbpKUAvY8y0S9r9HvgD4AsMMsb8YqxCRKYCUwHCw8MTFixYUK3QOTk5BAYGVmtdZ03bPI0G0oBXujk2nu7KbM7QXM7RXM5z12yelisxMXGTMaZHhQuNMZf9AcYD/yw3PQV47TLtJwNzqnrehIQEU10rV66s9rrO+u2S35qQ50NMSUmJQ+1dmc0Zmss5mst57prN03IBG00lddWRIZd0oGW56RbAscu0XwCMduB564TOYZ3JzMvUQxiVUm7PkYK+AWgnIrEi4gtMApaUbyAi7cpN3gx4zKEhncI6AbDt1DaLkyil1OVVWdCNMUXANGA5sAv42BizQ0SeEpGR9mbTRGSHiKRgG0e/o9YSu1jn8M4AbD+13eIkSil1eQ0caWSMWQosvWTeE+UeP1DDudxGqH8oEYER2kNXSrk9PVPUAZ3COrHtpBZ0pZR704LugM5hndmZsZPikuKyebN+msXi3YstTKWUUhfTgu6AruFdySvKY/fp3QDkFuYyfdl0nvzuSWuDKaVUOVrQHdA3ui8Aqw6vAuDr/V+TW5jL1pNbyb6QbWU0pZQqowXdAW2atiEyMLKsoC/ctRCAElOi9x9VSrkNLegOEBH6t+rP94e+p6C4gM/3fM64uHEIwpoja6yOp5RSgBZ0h/WP7k/6uXReWPMCWRey+HW3X9M5vDM/HPnB6mhKKQVoQXfY9a2uB+DxlY/Tu0VvhrQZQt+WfVmbvvaio1+UUsoqWtAd1CmsE00bNiUiMIKFExbi4+1D35Z9yS7I1rNIlVJuwaEzRRV4iReLJi4iPDCcqKAo4L+XBdiTuYeuEV2tjKeUUlrQnTEgZsBF022atgHQ29QppdyCDrlcgQDfAKKCokj9OdXqKEoppQX9SrVt1pbUM1rQlVLW04J+hdo21YKulHIPWtCvUNtmbTmRc0IvAaCUspwW9CvULsR2s6b9P++3OIlSqr7Tgn6F2jZrC8Di3Ytp/3p7DuQcAODHIz9SVFJkZTSlVD2jBf0KlR66+Nfv/8rezL0sPraY/+z/D33e68OiXYssTqeUqk/0OPQrFOQXRHhAOCfPnyTUP5QVGSvIWZMDUHb9dKWUcgXtodeAzuGdadesHXNGzyGnKIcVB1cAcPDsQYuTKaXqE+2h14B5Y+cBENIohOZ+zTlXdI7YprEc+PmAxcmUUvWJFvQaEBYQVvb4oXYPEdUmim8Pfst3h76zMJVSqr7RIZcadl3IddzR7Q5im8RyJOsIBcUFVkdSStUTWtBrSeumrTEYDmcdtjqKUqqe0IJeS2KbxgLoOLpSymW0oNeS1k1bA1rQlVKuowW9lkQFReHr7cvBn/XQRaWUa2hBryVe4kVMkxgOnNUeulLKNbSg16LYJnosulLKdbSg16KrQ65mb+ZeSkyJ1VGUUvWAFvRa1CW8CzkFOaSdTbM6ilKqHnCooItIkojsEZFUEZlRwfI/iMhOEdkqIt+KSKuaj1r3dAnvAsDWk1stTqKUqg+qLOgi4g28AQwDOgK3ikjHS5ptBnoYY7oAnwIv1HTQuii+eTyCaEFXSrmEIz30nkCqMeaAMaYAWACMKt/AGLPSGJNrn1wLtKjZmHVTgG8AbZu11YKulHIJRwr6VcCRctPp9nmV+Q3w1ZWE8iRdwrtoQVdKuYQYYy7fQGQ8MNQYc7d9egrQ0xhzfwVtfwVMAwYYYy5UsHwqMBUgPDw8YcGCBdUKnZOTQ2BgYLXWrW2XZpuTNoc5h+bwZb8vaeTdyG1yuQvN5Rx3zQXum83TciUmJm4yxvSocKEx5rI/wHXA8nLTjwKPVtDuBmAXEFbVcxpjSEhIMNW1cuXKaq9b2y7NtmjXIsOTmB+P/GhNIDt33WaayznumssY983mabmAjaaSuurIkMsGoJ2IxIqILzAJWFK+gYhcA7wDjDTGnHL6V44H6xbRDYDr37+eiZ9OtDiNUsqTVVnQjTFF2IZRlmPrgX9sjNkhIk+JyEh7sxeBQOATEUkRkSWVPF29E9Mkhq9u+4qb2t3Exzs+5ui5o2XLCooL9KQjpVSNceg4dGPMUmPM1caYNsaYmfZ5Txhjltgf32CMCTfGdLP/jLz8M9YvSW2T+POAPwOwMm0lJaaE19a9RpPnmvD6+tctTqeU8hR6pqiLdI3oSrNGzfj24Lc8/f3TTF82nbyiPNYcWWN1NKWUh9B7irqIl3iRGJPI8tTlnC88z5gOY8gvymf36d1WR1NKeQjtobvQoNhBHM85zrkL53hiwBPEhcaxL3OfjqMrpWqEFnQXGhQ7CIDhVw+nW0Q3OoR2IK8ojyNZRy5qt+rQKlLPpFoRUSlVh2lBd6H2Ie15Zegr/D3p77bp0PYAFw27ZOVnkTQviSdWPmFJRqVU3aUF3YVEhAd6P1B2v9EOoR0A2JO5p6zN3K1zyS3MJf1cuiUZlVJ1lxZ0CzX3b06Thk3KeujGGN7a+BYAx3OOWxlNKVUHaUG3kIjQIbRDWQ99zZE17MzYSWRgJMeyj5VeUkEppRyiBd1i7UPal/XQl+5bSgOvBtyTcA+5hblkF2RbnE4pVZdoQbdYx+YdOZZ9jIzzGaw+vJqEyATahbQD4Fj2MYvTKaXqEi3oFhscOxiARbsXsf7oevpF9yMqKArQgq6Uco4WdIt1j+xOVFAUz6x6hgvFF+jbsi+RgZEAHM/WHaNKKcdpQbeYiDDi6hEcyjoEQN/ovtpDV0pVixZ0NzDi6hEAXB1yNWEBYQT5BRHoG6iHLiqlnKIF3Q0Mih1EoG8gA1oNKJtXeuiiUko5Sq+26AYa+TRi7W/WEhEYUTYvKihKC7pSyinaQ3cT8WHxhPiHlE1HBkXqkItSyila0N1UVGCUni2qlHKKFnQ3FRUUpWeLKqWcogXdTZVekfHWhbeyL3OfxWmUUnWBFnQ3NarDKJ4Z9AxrDq9h8meTrY6jlKoD9CgXN+UlXjza/1ECfQOZvmw6KSdS6BbRzepYSik3pj10N3dbl9vw8/Zj1k+zrI6ilHJzWtDdXLNGzRgbN5YPtn3A6dzTVsdRSrkxLeh1wLSe0zh34Ryt/96aV9e9anUcpZSb0oJeB/Rp2Yct926hX3Q/Hlj2AM+seoaDPx8k43yGHqeulCqjBb2O6BTWic9v/ZxJnSbx2IrHaP1qa8L+Fkb438L5/tD3VsdTSrkBPcqlDvH28mbumLmM7TCW84XnycrP4pV1rzD186lsvW8rvt6+VkdUSllIC3od08CrAePjx5dNXx1yNTfNv4kZ38zgt91/S1zzOAvTKaWspEMuddywdsOYED+Bl9e+TMc3O/LoN49aHUkpZREt6B5g/tj5bJq6iTu73clza57j/c3vA/DZrs+45eNbdMepUvWEDrl4AG8vb7pHdufd4e+Sfi6d+768j2uvupbpX03naPZRTuScsDqiUsoFHOqhi0iSiOwRkVQRmVHB8utF5CcRKRKRW2o+pnKEj7cPc0bPwa+BHwNmD+Bo9lEAdmbs5OeCn/l056cWJ1RK1aYqC7qIeANvAMOAjsCtItLxkmaHgTuB+TUdUDknKiiKZwY9w5m8M3QJ7wLAjowdfJr+KeM/Gc/hrMMWJ1RK1RZHhlx6AqnGmAMAIrIAGAXsLG1gjEmzLyuphYzKSff2uJecghzGxo2l1z97sTNjJ9vPbQfgxyM/Eh0cbXFCpVRtkKp2mNmHUJKMMXfbp6cAvYwx0ypoOxv4whhT4d/2IjIVmAoQHh6esGDBgmqFzsnJITAwsFrr1jZ3y3b/5vspMSWk5qRSYAoYd9U4prX9xUdnGXfbXqU0l/PcNZun5UpMTNxkjOlR0TJHeuhSwbxqHTZhjHkXeBegR48eZuDAgdV5GpKTk6nuurXN3bL1ye7Duz+9C4C3eHOEIwwcOJDcwlz8ffwtTud+26uU5nKeu2arT7kc2SmaDrQsN90C0NvR1xHxYfFljyfET2Dz8c28sOYFmj3fjKX7llqYTClV0xwp6BuAdiISKyK+wCRgSe3GUjWlY3Pb/utQ31AmxE+gsKSQGd/MoLCkkFs+voW16WstTqiUqilVFnRjTBEwDVgO7AI+NsbsEJGnRGQkgIhcKyLpwHjgHRHZUZuhlePim9t66HGN47iuxXUA+DXw44e7fiAiMILbF91OQXEBxhiKS4qtjKqUukIOnVhkjFkKLL1k3hPlHm/ANhSj3ExEYAS3dLyFbtKN8MBwxsWNY2DMQHq16MWbN7/JsHnDeHDZgyzfv5wbYm/gnRHvWB1ZKVVNeqaohxMRPhn/CcnJyQB8OuG/ByAltU3i5nY389bGtwBYdGERbw9/G5GK9oMrpdydFvR67o2b3iD2h1hC/EP4y3d/YW/mXtqHtrc6llKqGvTiXPVcqyateO2m15jUaRIAqw6vumh5UUkRBcUFF807X3DeZfmUUo7Tgq4AaB/SnlD/0F8U9Dv/fSeD/zW4bDr1TCrNX2zOPzb9w9URlVJV0IKuANtYe7/ofqw6tIr0c+lknM8gpyCHhbsWsvrwag7+fBCAmatmkleUx1PfP8WFogsWp1ZKlacFXZXpH92fg2cPEv1yNANmD+CLvV+QX5QPwOI9i9l/Zj9zt8yld4vepJ9LZ86WORYnVkqVpwVdlRkXN47+0f25rctt7Dq9iweWPUCofygdm3dk4a6FPLT8IXy8ffhswmf0uqoXL/7wotWRlVLlaEFXZVo1acX3v/6ef43+F9dGXcup86cY3X404+LGsfrwaj7f+zkv3PACkUGRTIifQOqZVE6dPwXA8tTldH27a9ndkpRSrqcFXf2CiPD8Dc/jLd5M7jyZCfETaODVgAd7Pcj9ve4HoFtENwC2nNjCnJQ5JM1LYtvJbfzfyv8rG1tPO5vG098//YujZJRStUMLuqpQYmwimf+TSWJsIp3COnH0D0d5aehLZcu7hncFYMvJLSzYsYB2zdqx5NYlHMs+xtytcwG478v7eHzl47y54U2HX3d56nIKiwtr9s0oVU9oQVeVCm4YXPY4LCDsojNIQ/xDaNG4BRuPbWT14dXc0PoGbm53M90ju/Ps6md5b/N7LEtdRrBfMH/57i9k5mZW+Xobj20kaV4S87fpja+Uqg4t6KraukV0Y/GexeQU5DAwZiAiwgs3vMDJnJP8ZslvaNm4Jd/e/i3nLpxj5qqZVT7f6sOrAdh0fFNtR1fKI2lBV9XWLbxb2WGNA1oNAGBw68GkTk/lkeseYfbo2SREJTC582T+8dM/yMrPumj91DOppOeml03/cOQHAFJOpLjoHSjlWbSgq2or3THaIbQD4YHhZfMjAiN4cciLDIodBMCDvR4kpyCHWZtnlbUxxjDiwxE8vPVh8ovyMcaw5sgawFbQS4zenlYpZ2lBV9VWWtAHthp42XYJUQn0j+7Pq+tepaikCLCNl+8+vZtTF07x7sV3CvQAABIJSURBVKZ3OXLuCMeyj9E1vCvZBdllZ6YqpRynBV1VW+umrflTvz8xrWfVN51+pM8jHMo6xFsbbJfqnbt1Ln7efsQFxTFz1UwW714MwO+u/R1g66WvOrSK9za/x6pDqyp8TmMMdy+5m092fFJD70ipuk0vn6uqTUSYObjqnZ0AI64ewdA2Q/nTij8xKHYQC7YvYET7EST6JfLAlgeYvmw6/j7+TO48md99+TueXvV02Vi6IPxnyn8Y3HowuYW53PPFPUyMn4i/jz+zNs9i9+ndjI8fX5tvVak6QXvoyiVEhLdufovikmI6vdWJjNwMpnSZQsfGHdly7xYmdZrEtGunEegbSFzzOFJOpNAvuh97p+0lrnkckz+bzKZjm5j6+VQ+2PoBty+6nT8n/xmAtelrOZt/1uJ3qJT1tKArl4ltGsvnt37OS0Ne4rMJnzHi6hGA7UbWH477kOdvfB6A61pcR6h/KB+O+5B2Ie34ZPwn5Bfl0+MfPZi3bR53X3M35wvPs/rwaoa0GUKxKebbA99SWFyIMabKHAXFBfwl+S+cyDlRq+9XKVfTgq5canDrwTx03UOMiRtT6a3u/p70d3b/fjctGttuU9uxeUdS70/lneHv8Nzg53hnxDs8nfg0UUFRzB41m8Z+jfnX1n/R4Y0OJM5J/MXhkZdavHsxT373JA9//TCnc08z8dOJbD25tcbfq1KupmPoyu008mlEI59GF81rHtCcqQlTy6b/2PePPHTdQzTwasDg2MEs2r0Ifx9/jmQdYcDsAbyS9Ap9W/blQvEFAn0DKSwu5PtD3zMgZgAfbv8QgPnb5rMzYycpJ1Lw9/Hn/VGOXVisqKQIL/HCS7Q/pNyLFnRVZzXwsn19J8ZP5Mt9X/LJ+E/wEi9uX3Q7iXMSy9oNv3o4aWfT2H5qO/f1uI8v933JXd3u4ot9X5ByIoWYJjEs3r2YwuGF+Hj7AJBxIYP7l96PwdA/uj8T4idQbIp5c8ObPPXdUwyIGcCn4z/VG2ort6IFXdV5EztNZET7Efj7+ANw6MFDzN82n/Rz6eQW5vJeyns0atCIYW2H8dZG22GT9/S4hyldp7AzYydRQVGM+WgMyWnJtGnWhjc3vMkb69/AiMHX25c3NrzB0eyjrD+6no92fERcaByf7fqM19a/xvRe0wEoLinG28u7wnxpZ9PIOJ/BtVdd65oNouotLejKI5QWc7AN2fym+2/Kpp8Z/Axe4kVeUR493u1BsSnm2qhrEREGxgwkrzCPAJ8AHlz+IHsz9wJwfej1zLp1FtHB0Yz7eBwPf/0wAM/f8Dx/7PNHRi0YxR//80faNWtH2tk0Hlr+EFMTpjK913SyL2SzYPsCfL19GddxHEkfJJF1IYudv9tJbNPYi3LvOb2HP634E7/q/CvGxI0BbDttd5/eTZfwLrW92ZSH0YKuPF5pz9nfx5/Vd63mQtGFi4ZKGvk0YvjVw/lox0dMiJ/AS0NeYt9P+4hpEgPAB2M+YNLCSfRp0Yf/6fs/AMwePZsb597IyAUjKSopIi40jtfXv85r618DbMNBxSXFPL3qaUIaheAt3jy4/EH+t+//kpyWzOGswxzOOszKtJXkF+Xz9f6v2Ry+mYjACEYtGMWKgyt4++a3uafHPeQW5vLoN4/SpGETruf6Ct9jYXEhv/vyd+z/eT9Lbl1CoG9gLW5R5a60oKt6pVmjZhXO/3vS37m3x70MaDUAEWEf+8qWBfgG8Pmtn//ieVbcvoKJn04kxD+E90e9z66MXfx0/Cd8vH0Y0mYIB34+wIs/vMiMvjNYcXAFM76dwZI9SwAI9Q8lOjia2zrfxj0J9zD0g6EMmjMIEeHouaNcE3ENv1v6OzYd38Ta9LVsO7UNgE6NOzHajGZQ7CASY237Cc7kneGOf9/BF3u/QBBuXXgrg2IGUWyKefi6h3Wcvx7Rgq4UEB4YftEFxhwR3DCYZb9aVjbdNaIrXSO6lk2HBYSxcMLCsmVn8s7QIbQDY+PGXnSteYAPx33IU98/RUijEN6++W2ub3U94z4ex8JdCwn2C+bLyV9yOvc0Dy19iGdWP8PMVTN5rP9jNPJpxCtrX+FM3hnevOlNSkwJ076axhd7vwDgWPYxEmMS2XBsAw28GjA2biydwjrxw5Ef8BIvekT1KNu5XCq3MJfFuxcztO1QMs5nMGfLHIa0GVL2y64iW09uJb84v2z60NlDzN06l/CAcMZ1HFfpL1JVs7SgK+UCvt6+ZSdOVWRo26EMbTv0onnlf1mUiv45ml59e3HXkrt4etXTAPSP7s9rw14r+2USHxZPq+BWvPTjS7y89mVeXvty2fozV82k11W9WHXYdn2cJg2bML7jeB7s/SAdm3fkRM4JRn44kg3HNhDoG0hBcQEFxQU8u/pZrom4huFXD2dZ6jJOnT/FxPiJPNznYX46/hPD5g2jW3A3EgckkluYy5APhpTtj5i1eRZr7lpz0U7j/Wf28/bGt1l/bD2PX/84N7S+ocLtYozhox0fERkYyXUtr8PX29eRze2Qkzkn+cPXf2B0+9Hc0vGWKv+SKSguYOgHQxnQagBPDnyyxnLUJC3oStUxjXwaMX/sfB657hGig6NpHtD8ouUDYwYC8Pdhfyc+LJ7o4GhubH0jZ/PPct+X97EsdRnPDX6O1k1bs2TvEuZtm8ecLXO4vcvtfLb7M/KL8nnr5rdYm76Whg0a8mi/R1m6byn/3PxP/vr9X+nYvCOdwjrx0tqXmLdtHgXFBUQFRZGSlcKNc28su1rmyjtWknY2jV8v/jUvr32ZR/o8AsBPx38icY6t8IcFhDH0g6FM7T6VXi16MTZuLOvS1zF92XSeHPAkmXmZ/H7p7wHbZZn/MeIfDGg1gDN5Zzibf5Z2Ie3KdohvPr6ZF354gRUHV9CmaRse7fco7ULacb7oPHmFeSzavQiAsXFjKTEljFwwkvVH1zN/23yuibiGftH9+P7Q9+QW5vKfKf8h1D+Uk+dP0rppawDe2vAWyWnJJKcl065Zu7K/bHpe1fOind0bj20kvyifftH9au9LUAlx5FTp2tCjRw+zcePGaq2bnJzMwIEDazZQDXHXbJrLOZ6cq6ik6KJhlozzGdz9+d0s2bOEm9rdxPM3PE+nsE4VrpuZm0mzRs0QEVJOpDDu43GcyDnBxt9u5PXlr7Po5CKCGwbz+PWPM7nzZIwxjPloDIv3LCYsIIwWjVtw4OcDNPZrzHd3fkeofyj3fXkfC3cuJK8oj8Z+jTlfcB4v8cJg8BZvEmMTmdp9Kn9O/nPZvoRSTRo2YXSH0RhjmLdtHsF+wQxpM4TVh1dz5NyRsnZ+3n5cKLbdvDzINwiD4XzBeT6d8GnZsNKGYxvoHtmdvZl7aezXmPyifDJzM3l/1Pvc0PoG4t+M55rIa8jKz/rFXbXim8czLm4cQX5BPPrtoxSVFDGmwxge6/8Yu0/v5onkJ4gIjKBDSAe8vby5rfNtmDRTrc9SRDYZY3pUtEx76ErVM5eOmTcPaM6/J/6b4znHiQqKuuy6If4hZY+7RXRj671bOZN3hpbBLRnfYjxv/OqNi9qLCO+Pep+3Nr5F2tk0jmYfJSwgjNeHvV52FNHcMXOZPWo2G49t5JV1ryAIL974ImM/HsvhrMPMHjWb8MBwbmp3E7M2z+J8wXlC/EPw9/Fn8Z7FfLH3C0pMCbd1vo2Xhr5Es0bNuFB0geS0ZDLzMknenIx/mD+j2o+ixJTwyc5P8PX25cbWNzKive16Qvf0uIcSU4KXeLH+6HqSPkiia0RXjDHc/u/bEQQv8eLloS/TpGETZv00ixvb3Gg7curwaj7b9RlPr3qaElNCUtsk+rbsy3Ornyv7qyAhMgGAZfuXUWJK6Bfdj2iir+hzrJAxpsofIAnYA6QCMypY7gd8ZF++Doip6jkTEhJMda1cubLa69Y2d82muZyjuZxX09kKiwtNVn7WFT9PdXIVFRcZY4zJK8wzT6x4wjy58kmTcjzlsuuczDlpVhxYYQqLC40xxpzNO2teX/e6eWfjO2XPd6W5jDEG2GgqqatV9tBFxBt4A7gRSAc2iMgSY8zOcs1+A/xsjGkrIpOA54GJNfVLRylV/zTwakBjv8aWvHbpDtyGDRryl8S/OLROWEAYYbFhZdPBDYP5fc/f10q+yjhydaGeQKox5oAxpgBYAIy6pM0oYI798afAYNGDX5VSyqWq3CkqIrcAScaYu+3TU4Bexphp5dpst7dJt0/vt7c5fclzTQWmAoSHhycsWLCgWqFzcnIIDHTPM+HcNZvmco7mcp67ZvO0XImJiZXuFHVk/Hw88M9y01OA1y5pswNoUW56PxByuefVMXTX0lzO0VzOc9dsnpaLy4yhOzLkkg60LDfdAjhWWRsRaQAEA2cc+W2jlFKqZjhS0DcA7UQkVkR8gUnAkkvaLAHusD++BVhh/02ilFLKRao8ysUYUyQi04DlgDfwnjFmh4g8ha3rvwSYBcwVkVRsPfNJtRlaKaXULzl0YpExZimw9JJ5T5R7nI9trF0ppZRF9KaISinlISy7louIZACHqrl6KHC6ylbWcNdsmss5mst57prN03K1MsY0r2iBZQX9SojIRlPZcZgWc9dsmss5mst57pqtPuXSIRellPIQWtCVUspD1NWC/q7VAS7DXbNpLudoLue5a7Z6k6tOjqErpZT6pbraQ1dKKXUJLehKKeUh6lxBF5EkEdkjIqkiMsPCHC1FZKWI7BKRHSLygH3+kyJyVERS7D83WZAtTUS22V9/o31eMxH5j4jss//b1MWZ2pfbJikick5EHrRqe4nIeyJyyn7p59J5FW4jsXnV/p3bKiLdXZzrRRHZbX/tRSLSxD4/RkTyym27t12cq9LPTkQetW+vPSIytLZyXSbbR+VypYlIin2+S7bZZepD7X7HKrsMozv+YLuWzH6gNeALbAE6WpQlEuhufxwE7AU6Ak8Cj1i8ndKA0EvmvYD99oHADOB5iz/HE0Arq7YXcD3QHdhe1TYCbgK+AgToDaxzca4hQAP74+fL5Yop386C7VXhZ2f/f7AF260pY+3/Z71dme2S5f8PeMKV2+wy9aFWv2N1rYfuyN2TXMIYc9wY85P9cTawC7jKiiwOKn9XqTnAaAuzDAb2G2Oqe6bwFTPGfM8vL/Fc2TYaBfzL2KwFmohIpKtyGWO+NsYU2SfXYruEtUtVsr0qMwpYYIy5YIw5iO1ewz2tyCYiAkwAPqyt168kU2X1oVa/Y3WtoF8FHCk3nY4bFFERiQGuwXaDbIBp9j+b3nP10IadAb4WkU1iu0sUQLgx5jjYvmxAWKVr175JXPwfzOrtVaqybeRO37u7sPXkSsWKyGYR+U5E+luQp6LPzp22V3/gpDFmX7l5Lt1ml9SHWv2O1bWCXtF9Si097lJEAoGFwIPGmHPAW0AboBtwHNufe67W1xjTHRgG/F5ErrcgQ4XEdk39kcAn9lnusL2q4hbfOxF5DCgC5tlnHQeijTHXAH8A5ouIK++qXNln5xbby+5WLu48uHSbVVAfKm1awTynt1ldK+iO3D3JZUTEB9uHNc8Y8xmAMeakMabYGFMC/INa/FOzMsaYY/Z/TwGL7BlOlv4JZ//3lKtz2Q0DfjLGnLRntHx7lVPZNrL8eycidwDDgduMfdDVPqSRaX+8CdtY9dWuynSZz87y7QVld08bC3xUOs+V26yi+kAtf8fqWkF35O5JLmEfm5sF7DLGvFRufvlxrzHA9kvXreVcASISVPoY2w617Vx8V6k7gMWuzFXORT0mq7fXJSrbRkuA2+1HIvQGskr/bHYFEUkC/hcYaYzJLTe/uYh42x+3BtoBB1yYq7LPbgkwSUT8RCTWnmu9q3KVcwOw29hvXg+u22aV1Qdq+ztW23t7a2Hv8U3Y9hjvBx6zMEc/bH8SbQVS7D83AXOBbfb5S4BIF+dqje0Igy3Ybt79mH1+CPAtsM/+bzMLtpk/kAkEl5tnyfbC9kvlOFCIrXf0m8q2EbY/h9+wf+e2AT1cnCsV2/hq6ffsbXvbcfbPeAvwEzDCxbkq/eyAx+zbaw8wzNWfpX3+bODeS9q6ZJtdpj7U6ndMT/1XSikPUdeGXJRSSlVCC7pSSnkILehKKeUhtKArpZSH0IKulFIeQgu6Ukp5CC3oSinlIf4/gnQckwIrIPcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_loss_accu(h) # depth = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"best_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference & Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 128, 128, 64, 1)   0         \n",
      "_________________________________________________________________\n",
      "conv3d_6 (Conv3D)            (None, 126, 126, 62, 64)  1792      \n",
      "_________________________________________________________________\n",
      "max_pooling3d_6 (MaxPooling3 (None, 63, 63, 31, 64)    0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 63, 63, 31, 64)    256       \n",
      "_________________________________________________________________\n",
      "conv3d_8 (Conv3D)            (None, 61, 61, 29, 64)    110656    \n",
      "_________________________________________________________________\n",
      "max_pooling3d_8 (MaxPooling3 (None, 30, 30, 14, 64)    0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 30, 30, 14, 64)    256       \n",
      "_________________________________________________________________\n",
      "conv3d_9 (Conv3D)            (None, 28, 28, 12, 128)   221312    \n",
      "_________________________________________________________________\n",
      "max_pooling3d_9 (MaxPooling3 (None, 14, 14, 6, 128)    0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 14, 14, 6, 128)    512       \n",
      "_________________________________________________________________\n",
      "conv3d_10 (Conv3D)           (None, 12, 12, 4, 256)    884992    \n",
      "_________________________________________________________________\n",
      "max_pooling3d_10 (MaxPooling (None, 6, 6, 2, 256)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 6, 6, 2, 256)      1024      \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 18432)             0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 512)               9437696   \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 2)                 1026      \n",
      "=================================================================\n",
      "Total params: 10,659,522\n",
      "Trainable params: 10,658,498\n",
      "Non-trainable params: 1,024\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = None\n",
    "model = load_model(\"best_model.h5\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = expand_dims(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 128, 128, 64, 1)\n",
      "(1, 128, 128, 64, 1)\n",
      "(1, 128, 128, 64, 1)\n",
      "(1, 128, 128, 64, 1)\n",
      "(1, 128, 128, 64, 1)\n",
      "(1, 128, 128, 64, 1)\n",
      "(1, 128, 128, 64, 1)\n",
      "(1, 128, 128, 64, 1)\n",
      "(1, 128, 128, 64, 1)\n",
      "(1, 128, 128, 64, 1)\n",
      "(1, 128, 128, 64, 1)\n",
      "(1, 128, 128, 64, 1)\n",
      "(1, 128, 128, 64, 1)\n",
      "(1, 128, 128, 64, 1)\n",
      "(1, 128, 128, 64, 1)\n",
      "(1, 128, 128, 64, 1)\n",
      "(1, 128, 128, 64, 1)\n",
      "(1, 128, 128, 64, 1)\n",
      "(1, 128, 128, 64, 1)\n",
      "(1, 128, 128, 64, 1)\n",
      "(1, 128, 128, 64, 1)\n",
      "(1, 128, 128, 64, 1)\n",
      "(1, 128, 128, 64, 1)\n",
      "(1, 128, 128, 64, 1)\n",
      "(1, 128, 128, 64, 1)\n",
      "(1, 128, 128, 64, 1)\n",
      "(1, 128, 128, 64, 1)\n",
      "(1, 128, 128, 64, 1)\n",
      "(1, 128, 128, 64, 1)\n",
      "(1, 128, 128, 64, 1)\n",
      "(1, 128, 128, 64, 1)\n",
      "(1, 128, 128, 64, 1)\n",
      "(1, 128, 128, 64, 1)\n",
      "(1, 128, 128, 64, 1)\n",
      "(1, 128, 128, 64, 1)\n",
      "(1, 128, 128, 64, 1)\n",
      "(1, 128, 128, 64, 1)\n",
      "(1, 128, 128, 64, 1)\n",
      "(1, 128, 128, 64, 1)\n",
      "(1, 128, 128, 64, 1)\n",
      "(1, 128, 128, 64, 1)\n",
      "(1, 128, 128, 64, 1)\n",
      "(1, 128, 128, 64, 1)\n",
      "(1, 128, 128, 64, 1)\n",
      "(1, 128, 128, 64, 1)\n",
      "(1, 128, 128, 64, 1)\n",
      "(1, 128, 128, 64, 1)\n",
      "(1, 128, 128, 64, 1)\n",
      "(1, 128, 128, 64, 1)\n",
      "(1, 128, 128, 64, 1)\n",
      "(1, 128, 128, 64, 1)\n",
      "(1, 128, 128, 64, 1)\n",
      "(1, 128, 128, 64, 1)\n",
      "(1, 128, 128, 64, 1)\n",
      "(1, 128, 128, 64, 1)\n",
      "(1, 128, 128, 64, 1)\n",
      "(1, 128, 128, 64, 1)\n",
      "(1, 128, 128, 64, 1)\n",
      "(1, 128, 128, 64, 1)\n",
      "(1, 128, 128, 64, 1)\n",
      "(1, 128, 128, 64, 1)\n",
      "(1, 128, 128, 64, 1)\n",
      "(1, 128, 128, 64, 1)\n",
      "(1, 128, 128, 64, 1)\n",
      "(1, 128, 128, 64, 1)\n",
      "(1, 128, 128, 64, 1)\n",
      "(1, 128, 128, 64, 1)\n",
      "(1, 128, 128, 64, 1)\n",
      "(1, 128, 128, 64, 1)\n",
      "(1, 128, 128, 64, 1)\n",
      "(1, 128, 128, 64, 1)\n",
      "(1, 128, 128, 64, 1)\n",
      "(1, 128, 128, 64, 1)\n",
      "(1, 128, 128, 64, 1)\n",
      "(1, 128, 128, 64, 1)\n",
      "(1, 128, 128, 64, 1)\n",
      "(1, 128, 128, 64, 1)\n",
      "(1, 128, 128, 64, 1)\n",
      "(1, 128, 128, 64, 1)\n",
      "(1, 128, 128, 64, 1)\n",
      "(1, 128, 128, 64, 1)\n",
      "(1, 128, 128, 64, 1)\n",
      "(1, 128, 128, 64, 1)\n",
      "(1, 128, 128, 64, 1)\n",
      "(1, 128, 128, 64, 1)\n",
      "(1, 128, 128, 64, 1)\n",
      "(1, 128, 128, 64, 1)\n",
      "(1, 128, 128, 64, 1)\n",
      "(1, 128, 128, 64, 1)\n",
      "(1, 128, 128, 64, 1)\n",
      "(1, 128, 128, 64, 1)\n",
      "(1, 128, 128, 64, 1)\n",
      "(1, 128, 128, 64, 1)\n",
      "(1, 128, 128, 64, 1)\n",
      "(1, 128, 128, 64, 1)\n",
      "(1, 128, 128, 64, 1)\n",
      "(1, 128, 128, 64, 1)\n",
      "(1, 128, 128, 64, 1)\n",
      "(1, 128, 128, 64, 1)\n",
      "(1, 128, 128, 64, 1)\n",
      "(1, 128, 128, 64, 1)\n",
      "(1, 128, 128, 64, 1)\n",
      "(1, 128, 128, 64, 1)\n",
      "(1, 128, 128, 64, 1)\n",
      "(1, 128, 128, 64, 1)\n",
      "(1, 128, 128, 64, 1)\n",
      "(1, 128, 128, 64, 1)\n",
      "(1, 128, 128, 64, 1)\n",
      "(1, 128, 128, 64, 1)\n",
      "(1, 128, 128, 64, 1)\n",
      "(1, 128, 128, 64, 1)\n",
      "(1, 128, 128, 64, 1)\n",
      "(1, 128, 128, 64, 1)\n",
      "(1, 128, 128, 64, 1)\n",
      "(1, 128, 128, 64, 1)\n",
      "(1, 128, 128, 64, 1)\n",
      "(1, 128, 128, 64, 1)\n"
     ]
    }
   ],
   "source": [
    "res = []\n",
    "for i in x_test:\n",
    "    i = np.expand_dims(i, axis=0)\n",
    "    y_pred = model.predict(i)\n",
    "    res.append(y_pred)\n",
    "    print(i.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = np.array(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[2.53234301e-02, 9.32076156e-01]],\n",
       "\n",
       "       [[9.49556708e-01, 7.47595429e-02]],\n",
       "\n",
       "       [[9.66570914e-01, 9.08111334e-02]],\n",
       "\n",
       "       [[9.05116498e-01, 1.67651903e-02]],\n",
       "\n",
       "       [[7.62903273e-01, 3.47199917e-01]],\n",
       "\n",
       "       [[9.84465539e-01, 2.14268137e-02]],\n",
       "\n",
       "       [[4.88073200e-01, 5.72760284e-01]],\n",
       "\n",
       "       [[8.38962913e-01, 2.25058109e-01]],\n",
       "\n",
       "       [[2.16706231e-01, 4.99214679e-01]],\n",
       "\n",
       "       [[8.24397266e-01, 1.91924497e-01]],\n",
       "\n",
       "       [[8.85033906e-01, 8.12596604e-02]],\n",
       "\n",
       "       [[9.63601530e-01, 8.71849805e-02]],\n",
       "\n",
       "       [[7.98487723e-01, 2.83387363e-01]],\n",
       "\n",
       "       [[8.81968677e-01, 1.19600900e-01]],\n",
       "\n",
       "       [[9.90075648e-01, 4.58581373e-03]],\n",
       "\n",
       "       [[9.99198735e-01, 4.43978730e-04]],\n",
       "\n",
       "       [[6.68140292e-01, 4.64045495e-01]],\n",
       "\n",
       "       [[6.71015501e-01, 4.59583461e-01]],\n",
       "\n",
       "       [[3.05712223e-01, 5.43572307e-01]],\n",
       "\n",
       "       [[9.83097434e-01, 1.23935230e-02]],\n",
       "\n",
       "       [[7.38229334e-01, 1.89614683e-01]],\n",
       "\n",
       "       [[5.13376296e-03, 9.94171560e-01]],\n",
       "\n",
       "       [[1.71864584e-01, 9.25623238e-01]],\n",
       "\n",
       "       [[8.79902840e-01, 6.77307546e-02]],\n",
       "\n",
       "       [[1.72141165e-01, 8.29439282e-01]],\n",
       "\n",
       "       [[8.36406767e-01, 2.54851103e-01]],\n",
       "\n",
       "       [[1.98320404e-01, 9.21703100e-01]],\n",
       "\n",
       "       [[6.44496620e-01, 2.38120452e-01]],\n",
       "\n",
       "       [[9.04848993e-01, 1.30189925e-01]],\n",
       "\n",
       "       [[9.64185417e-01, 9.98102352e-02]],\n",
       "\n",
       "       [[8.32393289e-01, 4.22642231e-01]],\n",
       "\n",
       "       [[6.55945420e-01, 5.47351182e-01]],\n",
       "\n",
       "       [[6.25523984e-01, 4.71683830e-01]],\n",
       "\n",
       "       [[4.61576790e-01, 2.44149402e-01]],\n",
       "\n",
       "       [[2.32501298e-01, 3.97016257e-01]],\n",
       "\n",
       "       [[8.75787139e-02, 9.51807201e-01]],\n",
       "\n",
       "       [[2.21091695e-02, 9.95851398e-01]],\n",
       "\n",
       "       [[9.70487297e-01, 1.91924665e-02]],\n",
       "\n",
       "       [[9.81747448e-01, 4.72211689e-02]],\n",
       "\n",
       "       [[9.63558018e-01, 1.89320058e-01]],\n",
       "\n",
       "       [[5.33717632e-01, 6.91651106e-01]],\n",
       "\n",
       "       [[6.51306808e-01, 4.96479034e-01]],\n",
       "\n",
       "       [[9.06594455e-01, 7.91800544e-02]],\n",
       "\n",
       "       [[5.96536875e-01, 3.97939980e-01]],\n",
       "\n",
       "       [[9.18859482e-01, 8.61553624e-02]],\n",
       "\n",
       "       [[5.42919815e-01, 3.05959046e-01]],\n",
       "\n",
       "       [[1.48472667e-01, 8.20721567e-01]],\n",
       "\n",
       "       [[9.33727205e-01, 1.25145903e-02]],\n",
       "\n",
       "       [[3.15149277e-02, 9.88046050e-01]],\n",
       "\n",
       "       [[6.29307449e-01, 5.07149577e-01]],\n",
       "\n",
       "       [[9.68272686e-01, 1.62539613e-02]],\n",
       "\n",
       "       [[9.98987138e-01, 6.90141169e-04]],\n",
       "\n",
       "       [[8.84895742e-01, 4.04792845e-01]],\n",
       "\n",
       "       [[3.98316741e-01, 7.72516906e-01]],\n",
       "\n",
       "       [[8.57432187e-01, 1.16941698e-01]],\n",
       "\n",
       "       [[9.73016202e-01, 5.79914749e-02]],\n",
       "\n",
       "       [[2.03307077e-01, 8.12555611e-01]],\n",
       "\n",
       "       [[9.46242392e-01, 6.86431751e-02]],\n",
       "\n",
       "       [[1.94214389e-01, 7.88228452e-01]],\n",
       "\n",
       "       [[8.14530373e-01, 1.10963628e-01]],\n",
       "\n",
       "       [[3.29338521e-01, 7.33265340e-01]],\n",
       "\n",
       "       [[2.27259807e-02, 9.88751352e-01]],\n",
       "\n",
       "       [[6.47448063e-01, 6.92653894e-01]],\n",
       "\n",
       "       [[1.57425269e-01, 9.19131875e-01]],\n",
       "\n",
       "       [[2.89603285e-02, 9.48982000e-01]],\n",
       "\n",
       "       [[2.34032482e-01, 5.60414135e-01]],\n",
       "\n",
       "       [[8.52668166e-01, 3.57440144e-01]],\n",
       "\n",
       "       [[4.08849150e-01, 5.08097589e-01]],\n",
       "\n",
       "       [[6.65286720e-01, 2.46027365e-01]],\n",
       "\n",
       "       [[3.79787505e-01, 8.64327312e-01]],\n",
       "\n",
       "       [[9.90622222e-01, 6.06518984e-03]],\n",
       "\n",
       "       [[6.09395683e-01, 5.84800363e-01]],\n",
       "\n",
       "       [[9.54347432e-01, 9.78116989e-02]],\n",
       "\n",
       "       [[5.22700906e-01, 4.63723302e-01]],\n",
       "\n",
       "       [[9.91210103e-01, 1.40379055e-03]],\n",
       "\n",
       "       [[8.72325540e-01, 1.86251551e-01]],\n",
       "\n",
       "       [[9.33642387e-01, 1.23842023e-01]],\n",
       "\n",
       "       [[9.63513970e-01, 4.67741862e-02]],\n",
       "\n",
       "       [[3.56466502e-01, 6.46661520e-01]],\n",
       "\n",
       "       [[8.98627996e-01, 2.75617898e-01]],\n",
       "\n",
       "       [[9.69758153e-01, 2.47989465e-02]],\n",
       "\n",
       "       [[1.34050712e-01, 9.55887318e-01]],\n",
       "\n",
       "       [[9.30091202e-01, 4.09446470e-02]],\n",
       "\n",
       "       [[8.58394921e-01, 1.05594918e-01]],\n",
       "\n",
       "       [[9.91706610e-01, 7.04320334e-03]],\n",
       "\n",
       "       [[2.86485732e-01, 5.65192640e-01]],\n",
       "\n",
       "       [[8.97630394e-01, 3.86798270e-02]],\n",
       "\n",
       "       [[8.36493552e-01, 3.63234788e-01]],\n",
       "\n",
       "       [[4.30919051e-01, 3.40506017e-01]],\n",
       "\n",
       "       [[6.96976995e-03, 9.92737591e-01]],\n",
       "\n",
       "       [[7.10243404e-01, 8.50559592e-01]],\n",
       "\n",
       "       [[3.25272411e-01, 7.04087317e-01]],\n",
       "\n",
       "       [[4.67815064e-03, 9.96467471e-01]],\n",
       "\n",
       "       [[1.41609684e-01, 9.36888039e-01]],\n",
       "\n",
       "       [[4.30467069e-01, 7.84035087e-01]],\n",
       "\n",
       "       [[4.99598831e-01, 2.84562230e-01]],\n",
       "\n",
       "       [[6.62516594e-01, 2.04012260e-01]],\n",
       "\n",
       "       [[9.79081750e-01, 9.96022113e-03]],\n",
       "\n",
       "       [[5.51799417e-01, 6.29335523e-01]],\n",
       "\n",
       "       [[1.64803475e-01, 8.23658347e-01]],\n",
       "\n",
       "       [[8.28492820e-01, 1.18904434e-01]],\n",
       "\n",
       "       [[9.82804179e-01, 4.33210656e-02]],\n",
       "\n",
       "       [[2.54800290e-01, 8.68220031e-01]],\n",
       "\n",
       "       [[1.96219031e-02, 9.83752966e-01]],\n",
       "\n",
       "       [[2.05787364e-02, 9.90005672e-01]],\n",
       "\n",
       "       [[4.72149084e-04, 9.98993814e-01]],\n",
       "\n",
       "       [[9.08849359e-01, 7.23536760e-02]],\n",
       "\n",
       "       [[9.72429752e-01, 3.21128070e-02]],\n",
       "\n",
       "       [[8.15384865e-01, 2.72842318e-01]],\n",
       "\n",
       "       [[6.21615052e-01, 2.14800909e-01]],\n",
       "\n",
       "       [[5.59395850e-01, 2.51058280e-01]],\n",
       "\n",
       "       [[1.53615579e-01, 9.34244573e-01]],\n",
       "\n",
       "       [[7.23469019e-01, 2.14474499e-01]],\n",
       "\n",
       "       [[6.18226677e-02, 8.87830257e-01]],\n",
       "\n",
       "       [[7.80671597e-01, 1.28743425e-01]],\n",
       "\n",
       "       [[2.93084174e-01, 6.63750470e-01]],\n",
       "\n",
       "       [[1.77511334e-01, 8.15246403e-01]]], dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = res[:,:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22, 2)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import load_model\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>md_Disability</th>\n",
       "      <th>md_Relapse</th>\n",
       "      <th>md_SymptomsOfTB</th>\n",
       "      <th>md_Comorbidity</th>\n",
       "      <th>md_Bacillary</th>\n",
       "      <th>md_DrugResistance</th>\n",
       "      <th>md_HigherEducation</th>\n",
       "      <th>md_ExPrisoner</th>\n",
       "      <th>md_Alcoholic</th>\n",
       "      <th>md_Smoking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CTR_TST_001.nii.gz</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CTR_TST_002.nii.gz</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CTR_TST_003.nii.gz</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CTR_TST_004.nii.gz</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CTR_TST_005.nii.gz</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Filename  md_Disability  md_Relapse  md_SymptomsOfTB  \\\n",
       "0  CTR_TST_001.nii.gz              0           1                1   \n",
       "1  CTR_TST_002.nii.gz              0           1                0   \n",
       "2  CTR_TST_003.nii.gz              0           0                0   \n",
       "3  CTR_TST_004.nii.gz              0           1                1   \n",
       "4  CTR_TST_005.nii.gz              1           1                0   \n",
       "\n",
       "   md_Comorbidity  md_Bacillary  md_DrugResistance  md_HigherEducation  \\\n",
       "0               1             0                  0                   1   \n",
       "1               0             1                  4                   0   \n",
       "2               0             1                  3                   0   \n",
       "3               0             0                  0                   0   \n",
       "4               0             1                  3                   0   \n",
       "\n",
       "   md_ExPrisoner  md_Alcoholic  md_Smoking  \n",
       "0              0             0           0  \n",
       "1              0             0           1  \n",
       "2              0             0           1  \n",
       "3              0             1           1  \n",
       "4              0             0           1  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt = pd.read_csv('TestSet_metaData.csv')\n",
    "dt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "117"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patient_names = dt['Filename'].values\n",
    "len(patient_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CTR_TST_001',\n",
       " 'CTR_TST_002',\n",
       " 'CTR_TST_003',\n",
       " 'CTR_TST_004',\n",
       " 'CTR_TST_005',\n",
       " 'CTR_TST_006',\n",
       " 'CTR_TST_007',\n",
       " 'CTR_TST_008',\n",
       " 'CTR_TST_009',\n",
       " 'CTR_TST_010',\n",
       " 'CTR_TST_011',\n",
       " 'CTR_TST_012',\n",
       " 'CTR_TST_013',\n",
       " 'CTR_TST_014',\n",
       " 'CTR_TST_015',\n",
       " 'CTR_TST_016',\n",
       " 'CTR_TST_017',\n",
       " 'CTR_TST_018',\n",
       " 'CTR_TST_019',\n",
       " 'CTR_TST_020',\n",
       " 'CTR_TST_021',\n",
       " 'CTR_TST_022',\n",
       " 'CTR_TST_023',\n",
       " 'CTR_TST_024',\n",
       " 'CTR_TST_025',\n",
       " 'CTR_TST_026',\n",
       " 'CTR_TST_027',\n",
       " 'CTR_TST_028',\n",
       " 'CTR_TST_029',\n",
       " 'CTR_TST_030',\n",
       " 'CTR_TST_031',\n",
       " 'CTR_TST_032',\n",
       " 'CTR_TST_033',\n",
       " 'CTR_TST_034',\n",
       " 'CTR_TST_035',\n",
       " 'CTR_TST_036',\n",
       " 'CTR_TST_037',\n",
       " 'CTR_TST_038',\n",
       " 'CTR_TST_039',\n",
       " 'CTR_TST_040',\n",
       " 'CTR_TST_041',\n",
       " 'CTR_TST_042',\n",
       " 'CTR_TST_043',\n",
       " 'CTR_TST_044',\n",
       " 'CTR_TST_045',\n",
       " 'CTR_TST_046',\n",
       " 'CTR_TST_047',\n",
       " 'CTR_TST_048',\n",
       " 'CTR_TST_049',\n",
       " 'CTR_TST_050',\n",
       " 'CTR_TST_051',\n",
       " 'CTR_TST_052',\n",
       " 'CTR_TST_053',\n",
       " 'CTR_TST_054',\n",
       " 'CTR_TST_055',\n",
       " 'CTR_TST_056',\n",
       " 'CTR_TST_057',\n",
       " 'CTR_TST_058',\n",
       " 'CTR_TST_059',\n",
       " 'CTR_TST_060',\n",
       " 'CTR_TST_061',\n",
       " 'CTR_TST_062',\n",
       " 'CTR_TST_063',\n",
       " 'CTR_TST_064',\n",
       " 'CTR_TST_065',\n",
       " 'CTR_TST_066',\n",
       " 'CTR_TST_067',\n",
       " 'CTR_TST_068',\n",
       " 'CTR_TST_069',\n",
       " 'CTR_TST_070',\n",
       " 'CTR_TST_071',\n",
       " 'CTR_TST_072',\n",
       " 'CTR_TST_073',\n",
       " 'CTR_TST_074',\n",
       " 'CTR_TST_075',\n",
       " 'CTR_TST_076',\n",
       " 'CTR_TST_077',\n",
       " 'CTR_TST_078',\n",
       " 'CTR_TST_079',\n",
       " 'CTR_TST_080',\n",
       " 'CTR_TST_081',\n",
       " 'CTR_TST_082',\n",
       " 'CTR_TST_083',\n",
       " 'CTR_TST_084',\n",
       " 'CTR_TST_085',\n",
       " 'CTR_TST_086',\n",
       " 'CTR_TST_087',\n",
       " 'CTR_TST_088',\n",
       " 'CTR_TST_089',\n",
       " 'CTR_TST_090',\n",
       " 'CTR_TST_091',\n",
       " 'CTR_TST_092',\n",
       " 'CTR_TST_093',\n",
       " 'CTR_TST_094',\n",
       " 'CTR_TST_095',\n",
       " 'CTR_TST_096',\n",
       " 'CTR_TST_097',\n",
       " 'CTR_TST_098',\n",
       " 'CTR_TST_099',\n",
       " 'CTR_TST_100',\n",
       " 'CTR_TST_101',\n",
       " 'CTR_TST_102',\n",
       " 'CTR_TST_103',\n",
       " 'CTR_TST_104',\n",
       " 'CTR_TST_105',\n",
       " 'CTR_TST_106',\n",
       " 'CTR_TST_107',\n",
       " 'CTR_TST_108',\n",
       " 'CTR_TST_109',\n",
       " 'CTR_TST_110',\n",
       " 'CTR_TST_111',\n",
       " 'CTR_TST_112',\n",
       " 'CTR_TST_113',\n",
       " 'CTR_TST_114',\n",
       " 'CTR_TST_115',\n",
       " 'CTR_TST_116',\n",
       " 'CTR_TST_117']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names = []\n",
    "\n",
    "for name in patient_names:\n",
    "    names.append(name[:-7])\n",
    "\n",
    "names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.93207616,\n",
       " 0.07475954,\n",
       " 0.09081113,\n",
       " 0.01676519,\n",
       " 0.34719992,\n",
       " 0.021426814,\n",
       " 0.5727603,\n",
       " 0.22505811,\n",
       " 0.49921468,\n",
       " 0.1919245,\n",
       " 0.08125966,\n",
       " 0.08718498,\n",
       " 0.28338736,\n",
       " 0.1196009,\n",
       " 0.0045858137,\n",
       " 0.00044397873,\n",
       " 0.4640455,\n",
       " 0.45958346,\n",
       " 0.5435723,\n",
       " 0.012393523,\n",
       " 0.18961468,\n",
       " 0.99417156,\n",
       " 0.92562324,\n",
       " 0.067730755,\n",
       " 0.8294393,\n",
       " 0.2548511,\n",
       " 0.9217031,\n",
       " 0.23812045,\n",
       " 0.13018993,\n",
       " 0.099810235,\n",
       " 0.42264223,\n",
       " 0.5473512,\n",
       " 0.47168383,\n",
       " 0.2441494,\n",
       " 0.39701626,\n",
       " 0.9518072,\n",
       " 0.9958514,\n",
       " 0.019192467,\n",
       " 0.04722117,\n",
       " 0.18932006,\n",
       " 0.6916511,\n",
       " 0.49647903,\n",
       " 0.079180054,\n",
       " 0.39793998,\n",
       " 0.08615536,\n",
       " 0.30595905,\n",
       " 0.82072157,\n",
       " 0.01251459,\n",
       " 0.98804605,\n",
       " 0.5071496,\n",
       " 0.016253961,\n",
       " 0.00069014117,\n",
       " 0.40479285,\n",
       " 0.7725169,\n",
       " 0.1169417,\n",
       " 0.057991475,\n",
       " 0.8125556,\n",
       " 0.068643175,\n",
       " 0.78822845,\n",
       " 0.11096363,\n",
       " 0.73326534,\n",
       " 0.98875135,\n",
       " 0.6926539,\n",
       " 0.9191319,\n",
       " 0.948982,\n",
       " 0.56041414,\n",
       " 0.35744014,\n",
       " 0.5080976,\n",
       " 0.24602737,\n",
       " 0.8643273,\n",
       " 0.00606519,\n",
       " 0.58480036,\n",
       " 0.0978117,\n",
       " 0.4637233,\n",
       " 0.0014037905,\n",
       " 0.18625155,\n",
       " 0.12384202,\n",
       " 0.046774186,\n",
       " 0.6466615,\n",
       " 0.2756179,\n",
       " 0.024798946,\n",
       " 0.9558873,\n",
       " 0.040944647,\n",
       " 0.10559492,\n",
       " 0.0070432033,\n",
       " 0.56519264,\n",
       " 0.038679827,\n",
       " 0.3632348,\n",
       " 0.34050602,\n",
       " 0.9927376,\n",
       " 0.8505596,\n",
       " 0.7040873,\n",
       " 0.9964675,\n",
       " 0.93688804,\n",
       " 0.7840351,\n",
       " 0.28456223,\n",
       " 0.20401226,\n",
       " 0.009960221,\n",
       " 0.6293355,\n",
       " 0.82365835,\n",
       " 0.118904434,\n",
       " 0.043321066,\n",
       " 0.86822003,\n",
       " 0.98375297,\n",
       " 0.9900057,\n",
       " 0.9989938,\n",
       " 0.072353676,\n",
       " 0.032112807,\n",
       " 0.27284232,\n",
       " 0.21480091,\n",
       " 0.25105828,\n",
       " 0.9342446,\n",
       " 0.2144745,\n",
       " 0.88783026,\n",
       " 0.12874343,\n",
       " 0.66375047,\n",
       " 0.8152464]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probab = []\n",
    "\n",
    "for p in res:\n",
    "    # probability of HIGH severity as required to make submission\n",
    "    probab.append(p[0][1])\n",
    "    \n",
    "probab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CTR_TST_001 0.93207616\n",
      "CTR_TST_002 0.07475954\n",
      "CTR_TST_003 0.09081113\n",
      "CTR_TST_004 0.01676519\n",
      "CTR_TST_005 0.34719992\n",
      "CTR_TST_006 0.021426814\n",
      "CTR_TST_007 0.5727603\n",
      "CTR_TST_008 0.22505811\n",
      "CTR_TST_009 0.49921468\n",
      "CTR_TST_010 0.1919245\n",
      "CTR_TST_011 0.08125966\n",
      "CTR_TST_012 0.08718498\n",
      "CTR_TST_013 0.28338736\n",
      "CTR_TST_014 0.1196009\n",
      "CTR_TST_015 0.0045858137\n",
      "CTR_TST_016 0.00044397873\n",
      "CTR_TST_017 0.4640455\n",
      "CTR_TST_018 0.45958346\n",
      "CTR_TST_019 0.5435723\n",
      "CTR_TST_020 0.012393523\n",
      "CTR_TST_021 0.18961468\n",
      "CTR_TST_022 0.99417156\n",
      "CTR_TST_023 0.92562324\n",
      "CTR_TST_024 0.067730755\n",
      "CTR_TST_025 0.8294393\n",
      "CTR_TST_026 0.2548511\n",
      "CTR_TST_027 0.9217031\n",
      "CTR_TST_028 0.23812045\n",
      "CTR_TST_029 0.13018993\n",
      "CTR_TST_030 0.099810235\n",
      "CTR_TST_031 0.42264223\n",
      "CTR_TST_032 0.5473512\n",
      "CTR_TST_033 0.47168383\n",
      "CTR_TST_034 0.2441494\n",
      "CTR_TST_035 0.39701626\n",
      "CTR_TST_036 0.9518072\n",
      "CTR_TST_037 0.9958514\n",
      "CTR_TST_038 0.019192467\n",
      "CTR_TST_039 0.04722117\n",
      "CTR_TST_040 0.18932006\n",
      "CTR_TST_041 0.6916511\n",
      "CTR_TST_042 0.49647903\n",
      "CTR_TST_043 0.079180054\n",
      "CTR_TST_044 0.39793998\n",
      "CTR_TST_045 0.08615536\n",
      "CTR_TST_046 0.30595905\n",
      "CTR_TST_047 0.82072157\n",
      "CTR_TST_048 0.01251459\n",
      "CTR_TST_049 0.98804605\n",
      "CTR_TST_050 0.5071496\n",
      "CTR_TST_051 0.016253961\n",
      "CTR_TST_052 0.00069014117\n",
      "CTR_TST_053 0.40479285\n",
      "CTR_TST_054 0.7725169\n",
      "CTR_TST_055 0.1169417\n",
      "CTR_TST_056 0.057991475\n",
      "CTR_TST_057 0.8125556\n",
      "CTR_TST_058 0.068643175\n",
      "CTR_TST_059 0.78822845\n",
      "CTR_TST_060 0.11096363\n",
      "CTR_TST_061 0.73326534\n",
      "CTR_TST_062 0.98875135\n",
      "CTR_TST_063 0.6926539\n",
      "CTR_TST_064 0.9191319\n",
      "CTR_TST_065 0.948982\n",
      "CTR_TST_066 0.56041414\n",
      "CTR_TST_067 0.35744014\n",
      "CTR_TST_068 0.5080976\n",
      "CTR_TST_069 0.24602737\n",
      "CTR_TST_070 0.8643273\n",
      "CTR_TST_071 0.00606519\n",
      "CTR_TST_072 0.58480036\n",
      "CTR_TST_073 0.0978117\n",
      "CTR_TST_074 0.4637233\n",
      "CTR_TST_075 0.0014037905\n",
      "CTR_TST_076 0.18625155\n",
      "CTR_TST_077 0.12384202\n",
      "CTR_TST_078 0.046774186\n",
      "CTR_TST_079 0.6466615\n",
      "CTR_TST_080 0.2756179\n",
      "CTR_TST_081 0.024798946\n",
      "CTR_TST_082 0.9558873\n",
      "CTR_TST_083 0.040944647\n",
      "CTR_TST_084 0.10559492\n",
      "CTR_TST_085 0.0070432033\n",
      "CTR_TST_086 0.56519264\n",
      "CTR_TST_087 0.038679827\n",
      "CTR_TST_088 0.3632348\n",
      "CTR_TST_089 0.34050602\n",
      "CTR_TST_090 0.9927376\n",
      "CTR_TST_091 0.8505596\n",
      "CTR_TST_092 0.7040873\n",
      "CTR_TST_093 0.9964675\n",
      "CTR_TST_094 0.93688804\n",
      "CTR_TST_095 0.7840351\n",
      "CTR_TST_096 0.28456223\n",
      "CTR_TST_097 0.20401226\n",
      "CTR_TST_098 0.009960221\n",
      "CTR_TST_099 0.6293355\n",
      "CTR_TST_100 0.82365835\n",
      "CTR_TST_101 0.118904434\n",
      "CTR_TST_102 0.043321066\n",
      "CTR_TST_103 0.86822003\n",
      "CTR_TST_104 0.98375297\n",
      "CTR_TST_105 0.9900057\n",
      "CTR_TST_106 0.9989938\n",
      "CTR_TST_107 0.072353676\n",
      "CTR_TST_108 0.032112807\n",
      "CTR_TST_109 0.27284232\n",
      "CTR_TST_110 0.21480091\n",
      "CTR_TST_111 0.25105828\n",
      "CTR_TST_112 0.9342446\n",
      "CTR_TST_113 0.2144745\n",
      "CTR_TST_114 0.88783026\n",
      "CTR_TST_115 0.12874343\n",
      "CTR_TST_116 0.66375047\n",
      "CTR_TST_117 0.8152464\n"
     ]
    }
   ],
   "source": [
    "for n, p in zip(names, probab):\n",
    "    print(n, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CTR_TST_001 , 0.93207616\n",
      "CTR_TST_002 , 0.07475954\n",
      "CTR_TST_003 , 0.09081113\n",
      "CTR_TST_004 , 0.01676519\n",
      "CTR_TST_005 , 0.34719992\n",
      "CTR_TST_006 , 0.021426814\n",
      "CTR_TST_007 , 0.5727603\n",
      "CTR_TST_008 , 0.22505811\n",
      "CTR_TST_009 , 0.49921468\n",
      "CTR_TST_010 , 0.1919245\n",
      "CTR_TST_011 , 0.08125966\n",
      "CTR_TST_012 , 0.08718498\n",
      "CTR_TST_013 , 0.28338736\n",
      "CTR_TST_014 , 0.1196009\n",
      "CTR_TST_015 , 0.0045858137\n",
      "CTR_TST_016 , 0.00044397873\n",
      "CTR_TST_017 , 0.4640455\n",
      "CTR_TST_018 , 0.45958346\n",
      "CTR_TST_019 , 0.5435723\n",
      "CTR_TST_020 , 0.012393523\n",
      "CTR_TST_021 , 0.18961468\n",
      "CTR_TST_022 , 0.99417156\n",
      "CTR_TST_023 , 0.92562324\n",
      "CTR_TST_024 , 0.067730755\n",
      "CTR_TST_025 , 0.8294393\n",
      "CTR_TST_026 , 0.2548511\n",
      "CTR_TST_027 , 0.9217031\n",
      "CTR_TST_028 , 0.23812045\n",
      "CTR_TST_029 , 0.13018993\n",
      "CTR_TST_030 , 0.099810235\n",
      "CTR_TST_031 , 0.42264223\n",
      "CTR_TST_032 , 0.5473512\n",
      "CTR_TST_033 , 0.47168383\n",
      "CTR_TST_034 , 0.2441494\n",
      "CTR_TST_035 , 0.39701626\n",
      "CTR_TST_036 , 0.9518072\n",
      "CTR_TST_037 , 0.9958514\n",
      "CTR_TST_038 , 0.019192467\n",
      "CTR_TST_039 , 0.04722117\n",
      "CTR_TST_040 , 0.18932006\n",
      "CTR_TST_041 , 0.6916511\n",
      "CTR_TST_042 , 0.49647903\n",
      "CTR_TST_043 , 0.079180054\n",
      "CTR_TST_044 , 0.39793998\n",
      "CTR_TST_045 , 0.08615536\n",
      "CTR_TST_046 , 0.30595905\n",
      "CTR_TST_047 , 0.82072157\n",
      "CTR_TST_048 , 0.01251459\n",
      "CTR_TST_049 , 0.98804605\n",
      "CTR_TST_050 , 0.5071496\n",
      "CTR_TST_051 , 0.016253961\n",
      "CTR_TST_052 , 0.00069014117\n",
      "CTR_TST_053 , 0.40479285\n",
      "CTR_TST_054 , 0.7725169\n",
      "CTR_TST_055 , 0.1169417\n",
      "CTR_TST_056 , 0.057991475\n",
      "CTR_TST_057 , 0.8125556\n",
      "CTR_TST_058 , 0.068643175\n",
      "CTR_TST_059 , 0.78822845\n",
      "CTR_TST_060 , 0.11096363\n",
      "CTR_TST_061 , 0.73326534\n",
      "CTR_TST_062 , 0.98875135\n",
      "CTR_TST_063 , 0.6926539\n",
      "CTR_TST_064 , 0.9191319\n",
      "CTR_TST_065 , 0.948982\n",
      "CTR_TST_066 , 0.56041414\n",
      "CTR_TST_067 , 0.35744014\n",
      "CTR_TST_068 , 0.5080976\n",
      "CTR_TST_069 , 0.24602737\n",
      "CTR_TST_070 , 0.8643273\n",
      "CTR_TST_071 , 0.00606519\n",
      "CTR_TST_072 , 0.58480036\n",
      "CTR_TST_073 , 0.0978117\n",
      "CTR_TST_074 , 0.4637233\n",
      "CTR_TST_075 , 0.0014037905\n",
      "CTR_TST_076 , 0.18625155\n",
      "CTR_TST_077 , 0.12384202\n",
      "CTR_TST_078 , 0.046774186\n",
      "CTR_TST_079 , 0.6466615\n",
      "CTR_TST_080 , 0.2756179\n",
      "CTR_TST_081 , 0.024798946\n",
      "CTR_TST_082 , 0.9558873\n",
      "CTR_TST_083 , 0.040944647\n",
      "CTR_TST_084 , 0.10559492\n",
      "CTR_TST_085 , 0.0070432033\n",
      "CTR_TST_086 , 0.56519264\n",
      "CTR_TST_087 , 0.038679827\n",
      "CTR_TST_088 , 0.3632348\n",
      "CTR_TST_089 , 0.34050602\n",
      "CTR_TST_090 , 0.9927376\n",
      "CTR_TST_091 , 0.8505596\n",
      "CTR_TST_092 , 0.7040873\n",
      "CTR_TST_093 , 0.9964675\n",
      "CTR_TST_094 , 0.93688804\n",
      "CTR_TST_095 , 0.7840351\n",
      "CTR_TST_096 , 0.28456223\n",
      "CTR_TST_097 , 0.20401226\n",
      "CTR_TST_098 , 0.009960221\n",
      "CTR_TST_099 , 0.6293355\n",
      "CTR_TST_100 , 0.82365835\n",
      "CTR_TST_101 , 0.118904434\n",
      "CTR_TST_102 , 0.043321066\n",
      "CTR_TST_103 , 0.86822003\n",
      "CTR_TST_104 , 0.98375297\n",
      "CTR_TST_105 , 0.9900057\n",
      "CTR_TST_106 , 0.9989938\n",
      "CTR_TST_107 , 0.072353676\n",
      "CTR_TST_108 , 0.032112807\n",
      "CTR_TST_109 , 0.27284232\n",
      "CTR_TST_110 , 0.21480091\n",
      "CTR_TST_111 , 0.25105828\n",
      "CTR_TST_112 , 0.9342446\n",
      "CTR_TST_113 , 0.2144745\n",
      "CTR_TST_114 , 0.88783026\n",
      "CTR_TST_115 , 0.12874343\n",
      "CTR_TST_116 , 0.66375047\n",
      "CTR_TST_117 , 0.8152464\n"
     ]
    }
   ],
   "source": [
    "with open('submission_{}.txt'.format(path_model), 'w') as f:\n",
    "    for n, p in zip(names, probab):\n",
    "        print(n,\",\", p)\n",
    "        f.write(str(n))\n",
    "        f.write(\",\")\n",
    "        f.write(str(p))\n",
    "        f.write(\"\\n\")\n",
    "        \n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
